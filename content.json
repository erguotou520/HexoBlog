{"pages":[{"title":"About","text":"","link":"/about/index.html"},{"title":"Categories","text":"","link":"/categories/index.html"},{"title":"Tags","text":"","link":"/tags/index.html"}],"posts":[{"title":"Atom前端开发配置","text":"Atom开发插件集合 2017-03-21更新，去除不常用的插件 2017-08-31更新，添加highlight-selected插件 12345678910111213141516171819202122232425apm listCommunity Packages (28) /Users/erguotou/.atom/packages├── Stylus@3.1.0├── atom-beautify@0.29.17├── atom-material-ui@1.3.9├── autoclose-html@0.23.0├── busy-signal@1.3.0├── docblockr@0.9.3├── editorconfig@2.2.2├── emmet@2.4.3├── file-icons@2.0.17├── highlight-selected@0.13.1├── intentions@1.1.2├── language-gitignore@0.3.0├── language-vue@0.21.2├── linter@2.1.0├── linter-eslint@8.1.4├── linter-htmlhint@1.3.2├── linter-ui-default@1.2.1├── local-history@4.0.1├── minimap@4.26.8├── minimap-highlight-selected@4.5.0└── pigments@0.39.1└── (empty) 1apm install Stylus atom-beautify atom-material-ui autoclose-html busy-signal docblockr editorconfig emmet file-icons highlight-selected intentions language-gitignore language-vue linter linter-ui-default linter-eslint linter-htmlhint local-history minimap minimap-highlight-selected pigments UI配置 安装的是atom-material-ui主题，在mac上很多地方行高很高，需要修改其配置文件","link":"/atom-frontend-plugins.html"},{"title":"在Ghost中使用附件","text":"有不少人问过ghost能不能上传附件的问题，当然大家可能都知道Ghost可以上传图片，使用![]()可以插入一个图片。然后有人就尝试在选择图片时上传一个普通文件，可惜这样系统会报错。 这是因为ghost后台做了限制，当然，你可以改代码去掉这个限制，不过上传后的图片在image目录里，这与设计之初的本意不符。Ghost本就是一个极简的，专注于写作的博客系统，使用的是markdown来写作，因此也没有做上传附件这个功能。不过如果真的要在文章中使用附件怎么办呢？ 其实很简单，附件也不过只是个网络资源，你只需要将资源的url引用下就可以了。一种是自己用apache建一个静态文件服务器，比如我这个我的简单媒体工具。一种是使用云存储，然后获得文件的下载地址，比如使用七牛云存储。 这里以使用七牛为例，首先建一个静态目录的空间 ，关于空间的设置不做介绍，点击“空间管理”再点击“上传”，建议添加一个前缀，完成附件的上传。这时候在列表页面点击刚上传的文件，在右侧就可以获取到文件的外链。 通过上面2种方法得到了文件的外链后，只需要在博客中需要插入附件的地方插入[your title](刚获取到的外链地址)或者使用a标签&lt;a href=&quot;刚获取到的外链地址&quot; target=&quot;_blank&quot;&gt;链接显示的文字&lt;/a&gt;插入。a标签与markdown的语法相比，可以实现打开的页面是一个新的标签而不是覆盖当前的页面。最后，如果觉得默认的附件样式很丑，可以通过css来完善一下。下面附上我使用的附件。 自己服务器上的 七牛云存储的 .attachments { list-style: none; padding: 1em; background: #FFFE90; border: 1px solid #E4E4E4; } .attachments li:before { content: ''; display: inline-block; width: 18px; height: 18px; background-size: 100% 100%; margin-right: 8px; background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABIAAAASCAYAAABWzo5XAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAyZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuNS1jMDIxIDc5LjE1NTc3MiwgMjAxNC8wMS8xMy0xOTo0NDowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvIiB4bWxuczp4bXBNTT0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wL21tLyIgeG1sbnM6c3RSZWY9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9zVHlwZS9SZXNvdXJjZVJlZiMiIHhtcDpDcmVhdG9yVG9vbD0iQWRvYmUgUGhvdG9zaG9wIENDIDIwMTQgKFdpbmRvd3MpIiB4bXBNTTpJbnN0YW5jZUlEPSJ4bXAuaWlkOjZFMzkzMDREOUQ0RTExRTRCMEE5OEU4MUE4Q0QxNTZBIiB4bXBNTTpEb2N1bWVudElEPSJ4bXAuZGlkOjZFMzkzMDRFOUQ0RTExRTRCMEE5OEU4MUE4Q0QxNTZBIj4gPHhtcE1NOkRlcml2ZWRGcm9tIHN0UmVmOmluc3RhbmNlSUQ9InhtcC5paWQ6NkUzOTMwNEI5RDRFMTFFNEIwQTk4RTgxQThDRDE1NkEiIHN0UmVmOmRvY3VtZW50SUQ9InhtcC5kaWQ6NkUzOTMwNEM5RDRFMTFFNEIwQTk4RTgxQThDRDE1NkEiLz4gPC9yZGY6RGVzY3JpcHRpb24+IDwvcmRmOlJERj4gPC94OnhtcG1ldGE+IDw/eHBhY2tldCBlbmQ9InIiPz5OMX2LAAABV0lEQVR42pTSzStEURjH8Tneig1FNBvKTmoWSko0ChsLL4kslK1ssLDx0pSYnYVShplZs/E2YsEGf4PssPCy8Q8gub6nnlun23XnmVuf7p157v2d85xzTKz0awm9+MUP9j3Pu6ooIaASO/jGHN7RjZQxpkYbYgfMIR1Sa8VZmTIkgzcsB4u09cTtWRM0JWGpiHeqNUFd2JXnOMbcIuszyq1WE1SOTzTgAO43SSxiTbPQ/RjCCYYDIXdIsE4xE/LhNDpk5GPc4xCXOJcZDmDSHgNCHvwdcVvIynNW2olLO2n5vSEDvGICH8FZVCGPdee/epxiAT3/9W3bsvxZ7WHTqbfgRtakGUfFguw05/GFFadu12gbBRnI0+zKBRoj6rPY0rRWiAhJSotNmiC7xZ0h7/ThFu1R7bhBg7hGm1Mfl5BEsXXxg/wDOYIZvMhRqMMqHjVB9voTYADxfGp9UkgPWgAAAABJRU5ErkJggg%3D%3D); } .attachments li a { font-size:16px; color:#666; } .attachments li a:hover{ font-size:16px; color:#F60; } Nodejs v0.12.7 Mac OS Universal Webstorm 10.0.4 Mac OS BoosStrap 3","link":"/attachment-in-ghost.html"},{"title":"黑苹果安装记录","text":"因工作原因换台电脑，作为开发人员，肯定是优先Mac的，其次是Linux系，但Linux系系统在软件工具生态上还有些不足，而Mac无疑是最佳选择。虽然黑苹果可能会遇到一些意外事故，但是也挡不住我对它的喜爱，哈哈。 以下介绍基本都是参照https://www.tonymacx86.com/threads/unibeast-install-macos-mojave-on-any-supported-intel-based-pc.259381/#create_unibeast得来，有能力的还是去tonymacx86好好研究一番。 安装前准备 硬件准备 黑苹果安装中最大的问题就是驱动问题，所以最好是安装tonymacx86上推荐的配置去购买，但是我的机器已经是准备好的了，就跳过这一步，但是要通过搜索确认下自己的硬件安装黑苹果没有太大问题。我的主要配置如下： Intel I5 8400 MSI B310M 集成显卡 Intel UHD 630 另外你最好有一台白苹果，没有的话用Windows应该也可以，不过我更倾向于白苹果制作引导盘的方式。 除此意外你还需要准备一个8G以上（最好16G）的U盘用来做安装盘。 软件准备 首先你需要注册一个tonymacx86的账号，因为我们需要的工具以及教程基本上都是在这里找到的。 然后在下载Mac的系统安装文件，根据自己情况选择不同的方案。这里以macOS High Sierra 10.13.6版本为例（最新的Mojave版本感觉有不少问题，我的白苹果一直都没有升级），白苹果前往https://itunes.apple.com/cn/app/macos-high-sierra/id1246284741?ls=1&amp;mt=12下载。Windows系统可以通过下载集成clover的系统镜像配合TransMac工具制作启动盘进行安装，因为这个方式没有做过测试，所以不做过多介绍，各位可以自行搜索尝试，成功之后的操作应该都是一样的。 另外还需要在tonymacx86下载好MultiBeast和UniBeast工具，注意配合自己下载的系统版本。 这里需要将白苹果的系统语言改为英语，这是UniBeast的强制性要求，改完后重启。 安装流程 制作启动盘。插上U盘，在白苹果的磁盘工具中擦除U盘，格式选择Mac扩展（日志）。然后打开UniBeast按照流程进行启动盘制作，这里引导方式选择UEFI模式（一般新的电脑都是支持的）。制作完成后将MultiBeast应用拖到U盘中以备后用。 修改主板设置。让要安装黑苹果的电脑重启进入BIOS，关闭CPU的VT-D功能，关闭CFG-Lock，关闭主板的安全启动模式（Secure Boot Mode），关闭IO串口(IO Serial Port)，打开XHCI，硬盘调整为AHCI模式（一般新电脑都改成这种模式）。以上说的这些都是有则改之，无则跳过。然后修改U盘为第一启动盘，保存重启就可以进入Clover启动界面了。 准备安装。在Clover界面选择安装macOS系统，然后就等待安装吧，安装过程中可能会多次重启，重启后在Clover界面选择High Sierra来进行下一步安装。如果过程中出现什么错误（我就出现了叉号禁止符，并在之后一直无法进行下一步安装），那么在Clover界面选择启动参数设置（下面第2个还是第3个的）并追加 -v参数并重新进行之前操作，这样就可以将日志打印出来，找到你出错的那一行的关键信息进行搜索并找到解决方案。我出现的问题是通过在启动参数后追加-f UseKernelCache=No来解决了，有时可能还需要不断的重启或者更改U盘插的USB位置来修复，也是奇葩。 系统安装。第一次安装时需要将整个盘都擦除，同样是macOS扩展（日志）格式，安装完成后就是一些系统的初始化配置了，之后就进入我们的黑苹果系统了。 后续操作 使用MultiBeast安装各种驱动。将MultiBeast从U盘拖到应用程序中并启动，按照自己电脑硬件选择合适的驱动文件（鬼知道我应该勾选哪些驱动，除了个别是明确的，其它驱动都是看着最像或者凭感觉选的）并完成安装，之后重启电脑，这是基本上就可以拔掉U盘（这个启动盘后期还可以作为我们系统的修复引导工具）。 配置基本环境并安装工具。作为开发，我们还是要给我们的电脑安装些基础和必备的东西 Homebrew 这个在安装时可能很慢，所以需要提前找好梯子1/usr/bin/ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot; nvm NodeJs版本管理1curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.34.0/install.sh | bash Git1brew install git Xcode 一些命令行工具需要 Docker VSCode iTerm2 Alfred等 总结 安装黑苹果不难，但需要新手花点时间学习研究，遇到问题通过日志搜索，多逛逛tonymacx86。","link":"/black-mac-os.html"},{"title":"在Ghost中使用分类","text":"有不少刚接触Ghost博客的朋友都会问：Ghost如何做分类？如何按分类来浏览博客？其实Ghost没有分类这个概念，不像其它的博客系统，在发表文章时要选择分类，Ghost只有标签(Tag)。而我们正是要利用这个标签来变相地实现分类浏览。 首先说下Ghost添加标签的地方，还是有些人是不知道的。在如图位置输入标签，标签和标签之间以英文逗号隔开，会自动提示之前的标签： Ghost中的标签是没有限制的，给了我们很多自由，但如果要做分类，我们还是需要遵守一定规则为好，比如之前有篇文章有个标签test，那么你下一篇文章如果还要使用这个标签，在标签输入处输入t，Ghost会自动提示出之前的test分类，选择即可。这样我们就有2篇文章有相同的标签test了，这时候我们可以通过http://your.blog.site/tag/test来访问这个分类下的所有文章。 OK，现在我们已经完成了一半了，还有个问题是如何在我们的首页中显示分类信息呢？这里有几种方法，我们一一介绍。 第一种也是最简单最粗暴的方法，修改首页模板，在需要的位置添加一个到刚才的标签链接的a标签即可，该方法不做过多介绍，会网页基础的应该都会。 使用Ghost新的helpernavigation，这个需要你现在后台的设置里面加入相应的标签的链接即可。如图之后在模板中使用navigation来显示导航，关于该helper的使用，可以参考我翻译的文档。我们的GhostChina网站的导航就是使用了该方法，只不过它的导航链接都不是标签的，这里只是举例说明。 使用中文版中特有的标签tag_cloud，关于该标签的使用请查看。另外GhostChina网站也使用了该标签云。 这里简单地介绍了如何在Ghost中添加分类浏览，那么有人要问了，Ghost可以按日期来浏览文章么？其实Ghost可以在发表文章时选择在文章的链接上加上日期的，但是要实现按日期浏览文章暂时是没有的，起码我没有看到过，不过这个可以通过添加标签的方式来实现，期待高手出现。","link":"/category-in-ghost.html"},{"title":"CentOS7升级OpenSSH","text":"当前状态 查看openssh版本 ssh -V，查看openssl版本openssl version，记录当前版本号以便升级后做对比。 开启Telnet 升级ssh的过程中可能导致ssh无法登录，所以最好先开着Telnet。 123456789101112yum install xinetd telnet-server -ysystemctl enable xinetd.servicesystemctl enable telnet.socketsystemctl start telnet.socketsystemctl start xinetd# 允许root登录echo 'pts/0' &gt;&gt;/etc/securettyecho 'pts/1' &gt;&gt;/etc/securettysystemctl restart xinetd.service# 防火墙添加过滤firewall-cmd --add-service=telnet --zone=public --permanent# 确认下telnet是否可以登录成功 开始安装 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# 安装一些可能需要的库yum install zlib-devel -y pam-devel tcp_wrappers-devel gcc# 备份文件mv /usr/bin/openssl /usr/bin/openssl.bakmv /etc/ssh /etc/ssh.bak# 在/opt目录下载cd /opt# opensslwget https://www.openssl.org/source/openssl-1.0.2s.tar.gztar zxvf openssl-1.0.2s.tar.gz# openssl-fipswget https://www.openssl.org/source/openssl-fips-2.0.16.tar.gztar zxvf openssl-fips-2.0.16.tar.gz# opensshwget http://ftp.openbsd.org/pub/OpenBSD/OpenSSH/portable/openssh-8.0p1.tar.gztar zxvf openssh-8.0p1.tar.gz# 编译安装openssl-fipscd ./openssl-fips-2.0.16/./config &amp;&amp; make &amp;&amp; make install# 编译安装opensslcd ../openssl-1.0.2s/./config fips shared -fPICmake dependmake &amp;&amp; make installln -s /usr/local/ssl/bin/openssl /usr/bin/opensslln -s /usr/local/ssl/include/openssl /usr/include/opensslecho &quot;/usr/local/ssl/lib&quot; &gt;&gt; /etc/ld.so.conf/sbin/ldconfig# 查看版本是否升级成功openssl version# 编译安装opensshcd ../openssh-8.0p1./configure --prefix=/usr/ --sysconfdir=/etc/ssh --with-openssl-includes=/usr/local/ssl/include --with-ssl-dir=/usr/local/ssl --with-zlib --with-md5-passwords --with-pam &amp;&amp; make &amp;&amp; make install# 修改ssh配置文件，修改PermitRootLogin为yes UseDNS为novi /etc/ssh/sshd_configcp -a contrib/redhat/sshd.init /etc/init.d/sshdcp -a contrib/redhat/sshd.pam /etc/pam.d/sshd.pamchmod +x /etc/init.d/sshdchkconfig --add sshdsystemctl enable sshd# 使用命令测试端口是否正常systemctl stop sshdnetstat -lntpsystemctl start sshdnetstat -lntp 安装完成后续 安装完成后reboot重启下机器，然后测试下ssh版本是否升级成功 ssh -V，测试ok后关闭telnet服务 1234systemctl disable xinetd.servicesystemctl stop xinetd.servicesystemctl disable telnet.socketsystemctl stop telnet.socket","link":"/centos7-update-openssh.html"},{"title":"CI简介和实际应用","text":"什么是CI 引用知乎上的一个回答 作者：赵劼 链接：https://www.zhihu.com/question/23444990/answer/26995938 来源：知乎 著作权归作者所有，转载请联系作者获得授权。 集成是指软件个人研发的部分向软件整体部分交付，以便尽早发现个人开发部分的问题；部署是代码尽快向可运行的开发/测试节交付，以便尽早测试； 交付是指研发尽快向客户交付，以便尽早发现生产环境中存在的问题。 如果说等到所有东西都完成了才向下个环节交付，导致所有的问题只能再最后才爆发出来，解决成本巨大甚至无法解决。 而所谓的持续，就是说每完成一个完整的部分，就向下个环节交付，发现问题可以马上调整。是的问题不会放大到其他部分和后面的环节。 这种做法的核心思想在于：既然事实上难以做到事先完全了解完整的、正确的需求，那么就干脆一小块一小块的做，并且加快交付的速度和频率，使得交付物尽早在下个环节得到验证。早发现问题早返工。 举个例子，你家装修厨房，其中一项是铺地砖，边角地砖要切割大小。如果一次全切割完再铺上去，发现尺寸有误的话浪费和返工时间就大了，不如切一块铺一块。这就是持续集成。 装修厨房有很多部分，每个部分都有检测手段，如地砖铺完了要测试漏水与否，线路铺完了要通电测试电路通顺，水管装好了也要测试冷水热水。如果全部装完了再测，出现问题可能会互相影响，比如电路不行可能要把地砖给挖开……。那么每完成一部分就测试，这是持续部署。 全部装修完了，你去验收，发现地砖颜色不合意，水池太小，灶台位置不对，返工吗？所以不如没完成一部分，你就去用一下试用验收，这就是持续交付。 -------------------- 补充：从敏捷思想中提出的这三个观点，还强调一件事：通过技术手段自动化这三个工作。加快交付速度。 还有些细节可以参考阮一峰的文章 常用的持续集成工具 Travis CI 针对开源项目免费，私有项目收费 AppVeyou 主要是windows平台的持续集成 Gitlab CI 私有仓库Gitlab自带的CI Jenkins 同样的开源产品，适合私有仓库使用，但是需要jre环境来部署 项目实践 vue-fullstack 该项目为一个vue全栈项目模板，项目中使用travis做持续集成123456789101112131415161718192021language: node_jsnode_js: - &quot;6&quot;before_install: - git config --global push.default matching - git config --global user.name &quot;erguotou&quot; - git config --global user.email &quot;erguotou525@gmail.com&quot;install: - npm install -g vue-cli - npm install - node test/index.jsscript: - cd ../test-fullstack - npm install - npm run lint - npm run buildcache: directories: - node_modules - ../test-fullstack/node_modules - $(npm config get prefix)/vue-cli 该配置文件中主要就做了一件事，根据当前模板生成一个项目文件并执行代码检查和构建操作，以此来简单地验证模板生成的正确性。 TODO:最好可以添加一个文件结构验证的代码，另外后续会根据生成后的项目自动push到github的其它分支中，并通过heroku实现自动部署 electron-ssr 该项目是ShadowsocksR的一个多平台pc客户端，该项目同时使用了travis和appveyor用来构建不同平台上的安装包文件，简单的看下配置文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# travisosx_image: xcode7.3sudo: requireddist: trustylanguage: cmatrix: include: - os: osx - os: linux env: CC=clang CXX=clang++ npm_config_clang=1 compiler: clangaddons: apt: sources: - ubuntu-toolchain-r-test packages: - icnsutils - graphicsmagick - xz-utils - rpmcache: directories: - node_modules - app/node_modules - $HOME/.electron - $HOME/.cachebefore_install: - mkdir -p /tmp/git-lfs &amp;&amp; curl -L https://github.com/github/git-lfs/releases/download/v1.2.1/git-lfs-$([ &quot;$TRAVIS_OS_NAME&quot; == &quot;linux&quot; ] &amp;&amp; echo &quot;linux&quot; || echo &quot;darwin&quot;)-amd64-1.2.1.tar.gz | tar -xz -C /tmp/git-lfs --strip-components 1 &amp;&amp; /tmp/git-lfs/git-lfs pullinstall:- nvm install 6- npm install electron-builder- npm install- npm prunescript:- npm run buildbranches: only: - master 123456789101112131415161718192021222324252627282930version: 1.0.{build}platform: - x64cache: - node_modules - app\\node_modules - '%APPDATA%\\npm-cache' - '%USERPROFILE%\\.electron'branches: only: - masterinit: - git config --global core.autocrlf inputinstall: - ps: Install-Product node 6 x64 - git reset --hard HEAD - npm install npm -g - npm install electron-builder - npm install - npm prunebuild_script: - node --version - npm --version - npm run build 我们可以看到在travis中同时定义了Linux和Mac的构建任务，在appveyor中定义了Windows平台的构建任务。任务的大致流程都是根据当前的系统环境构建当前系统的安装包（打包App的任务由构建工具提供），然后自动发布到Gihub Release中，这样就实现了代码push-&gt;打包构建（全平台）-&gt;发布的完整过程，免去很多手动操作以及对系统环境的要求。 vio-frontend T2Cloud的VIO产品前端代码，集成Gitlab CI实现自动编译并发布到poc环境，配置文件如下：1234567891011121314151617181920212223242526272829303132333435363738stages: - install_deps - lint # - test - build - deploy_poc# 安装依赖install_deps: stage: install_deps script: - npm install --registry=https://registry.npm.taobao.orglint: stage: lint script: - npm run lint# 运行测试用例# test:# stage: test# only:# - develop# - master# script:# - npm run test# 编译build: stage: build only: - develop - master script: - npm run build# 部署测试服务器deploy_test: stage: deploy_poc only: - develop script: - npm run deploy 总结 简单的说，持续集成帮助我们开发人员免去很重复的手工操作任务，同时可以帮我们持续观察项目的构建状态，测试通过与否，实在是我们开发之幸。","link":"/ci.html"},{"title":"Ghost中添加评论系统","text":"Ghost系统默认是没有评论系统的，虽然官方也在关注这个问题，不过短时间内应该是不会有所进展，所以现在如果要在Ghost中使用评论，还是先使用第三方服务吧。下面介绍几种常见的评论系统，如果有更好的，欢迎来补充。 Disqus 一个国外的评论系统。首先注册一个账号，这个不多介绍，记得激活邮箱。进去后点击头像旁边的设置下拉里面的&quot;Add Disqus To Site&quot;, 然后在弹出的页面中根据情况设置属性， 完成后会跳到安装页面，在这里我们选择“Universal Code”， 最后我们复制页面中的脚本插入到Ghost的主题文件中，位置是/content/themes/[casper]/post.hbs文件的&lt;/article&gt;结束标签之前。 1234567891011121314151617&lt;article&gt; ... &lt;div id=&quot;disqus_thread&quot;&gt;&lt;/div&gt; &lt;script type=&quot;text/javascript&quot;&gt; /* * * CONFIGURATION VARIABLES * * */ /* * * 请将此处改为你自己的 * * */ var disqus_shortname = 'erguotou'; /* * * DON'T EDIT BELOW THIS LINE * * */ (function() { var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true; dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js'; (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq); })(); &lt;/script&gt; &lt;noscript&gt;Please enable JavaScript to view the &lt;a href=&quot;https://disqus.com/?ref_noscript&quot; rel=&quot;nofollow&quot;&gt;comments powered by Disqus.&lt;/a&gt;&lt;/noscript&gt;&lt;/article&gt; 到这里应该说基本是完成了，你已经可以在文章页面中看到Disqus的内容了，页面下面还有个统计评论数量的，这里不做介绍了。到这里基本上已经成功地使用上了Disqus，但是我们是不是可以做一点设置，让它更本地化，样式更好看呢？答案肯定是可以的，在Disqus的设置页面(Settings)中有很多设置，其中General选项卡中有一个Language，你可以选择Chinese，这样你的Disqus就是中文的了，这里还有很多其它设置，请自行研究。另外目前Disqus无法修改样式，虽然可以微调，然而并没有乱用啊。 2. 多说 一个国内的评论系统。同样是先登录，然后点击“我要安装”，根据自己情况填写， 然后选择通用代码－稳定版进行复制，同样插入到post.hbs文件的&lt;/article&gt;结束标签之前。复制后我们需要对复制的代码进行一些修改，我们将第一行修改为 1&lt;div class=&quot;ds-thread&quot; data-thread-key=&quot;{{id}}&quot; data-title=&quot;{{title}}&quot; data-url=&quot;{{url absolute=&quot;true&quot;}}&quot;&gt;&lt;/div&gt; 这样就完成来多说的安装，在多说的设置中有很多是我们可以调节的，多说支持自定义CSS，这样我们就可以将多说的评论框调成我们自己喜欢的样子，这部分请自行研究，这里不做过多介绍，我这个博客用的就是多说评论，自己简单的改了点样式。 3. 友言以及畅言等其它的第三方社会化评论系统都有类似的功能，安装方式大抵相同，欢迎大家自己研究，给出更多教程。 另外关于各个评论的比较，大家可以看下这篇文章，不过个人觉得畅言的样式更符合ghost一些。","link":"/comment-in-ghost.html"},{"title":"我是如何给Comunion开发环境做CI&#x2F;CD的","text":"项目介绍 Comunion是一个分布式的协作网络，通过区块链的技术去重新组织生产力和劳动的交易模式，从而实现全球劳动力、资源的自由、高效的流通和交易的一个平台💕。详情可以查看官网。 目前我在项目中主要负责前端开发和自动化打包发布等工作👷。 CI/CD 流程 分支命名约束 为了保证前后端仓库的 CI 配置文件可以通用，所以我们约定将master分支作为开发分支，将qa分支作为测试分支，prod分支作为线上版本分支。最终构建的 Docker 镜像在master分支将打上dev和latest标签，qa分支将打上qa标签，prod分支将打上prod标签。 Docker 打包配置 我们约定前后端同时使用 Docker 作为交付结果，所以前后端都要维护自己的Dockerfile甚至是docker-compose.yml。原本前端这边想的是可以做简单点，就只有一个nginx容器，通过volume挂载配合scp上传来实现。但是后来跟后端沟通了下既然后端是需要registry仓库的，那前端也就弄成完整镜像的形式吧。于是Dockerfile就类似下面的内容 1234567891011121314# build stageFROM node:lts-alpine as build-stageWORKDIR /appCOPY ./package*.json ./RUN yarn installCOPY . .RUN yarn run build# production stageFROM nginx:stable-alpine as production-stageCOPY --from=build-stage /app/dist /usr/share/nginx/htmlCOPY ./docker/nginx.conf /etc/nginx/conf.d/default.confEXPOSE 80CMD [&quot;nginx&quot;, &quot;-g&quot;, &quot;daemon off;&quot;] 其中 nginx.conf 的配置如下 123456789101112131415161718192021server { listen 80; server_name _ default_server; # charset utf-8; # access_log /var/log/nginx/log/access.log main; location / { root /usr/share/nginx/html; index index.html; try_files $uri $uri/ /index.html; } #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html { root html; }} 后端的打包逻辑大概就是go build各个模块，然后用alpine镜像拷贝 Golang 打包好的二进制文件，最后运行二进制文件这样的一个过程，具体可以查看后端代码。 Github actions 流程和配置 先看图👍 其中有几点需要说明。第一个在进行ssh登录并重启时提供的是ssh私钥，为了安全考虑加了一层passphrase，然后这些私密设置都是在Github secret里设置但，但从某种意义上来说这样也不能保证完全安全，毕竟这个appleboy/ssh-action action 也是可以利用收集到的数据进行 ssh 连接的，所以我们只是在开发环境这么使用，正式线上环境可以考虑自建 ci，风险可以自己把控。 另一个目前镜像是推送到自己到仓库里的，其实可以直接推到Docker Hub，毕竟我们本来就是源代码公开的。 还有一个是微信推送用的是国人维护的一个公众号推送服务，然后在Github action里封装了一层，但这个服务仍然有 down 的风险。 前后端流程基本一致，除了代码校验和打包发布的代码稍有不同，主体流程基本一致的。 部署机器环境准备 首先我们需要给机器安装好docker和docker-compose，这里不做过多说明。然后利用之前博客里提到的利用 Traefik 搭建超简单的 DevOps 平台的方案实现服务自动发现和自动添加https的功能，但是需要去掉Dashboard功能，traefik的配置如下： 12345678910111213141516171819202122232425262728293031version: &quot;3.7&quot;services: traefik: image: traefik:latest container_name: traefik command: - &quot;--api=true&quot; - &quot;--api.dashboard=false&quot; - &quot;--providers.docker=true&quot; - &quot;--providers.docker.network=traefik_webgateway&quot; - &quot;--providers.docker.exposedbydefault=false&quot; - &quot;--entryPoints.websecure.address=:443&quot; - &quot;--certificatesresolvers.mytlschallenge.acme.tlschallenge=true&quot; - &quot;--certificatesResolvers.mytlschallenge.acme.email=${ACME_EMAIL}&quot; - &quot;--certificatesResolvers.mytlschallenge.acme.storage=/etc/acme/acme.json&quot; labels: - &quot;traefik.enable=false&quot; networks: - traefik_webgateway ports: - &quot;443:443&quot; volumes: - &quot;./acme:/etc/acme&quot; - &quot;/var/run/docker.sock:/var/run/docker.sock:ro&quot; environment: - TZ=${TIME_ZONE}networks: traefik_webgateway: name: traefik_webgateway driver: bridge 然后我们需要准备registry和registry-ui作为docker容器仓库，这个和之前那篇文章一样，就不做过多介绍。接着创建前后端的目录，创建好前后端的docker-compose.yml配置文件，前端的配置文件蛮简单的 123456789101112131415161718192021version: &quot;3.7&quot;services: cos-front-com: image: registry.comunion.io/comunion/cos-front-com:dev container_name: cos-front-com restart: always networks: - traefik labels: - &quot;traefik.enable=true&quot; - &quot;traefik.docker.network=traefik_webgateway&quot; - &quot;traefik.http.services.cosFront.loadbalancer.server.port=80&quot; - &quot;traefik.http.routers.cosFront.rule=Host(`dev.${SERVER_DOMAIN}`)&quot; - &quot;traefik.http.routers.cosFront.entrypoints=websecure&quot; - &quot;traefik.http.routers.cosFront.tls.certresolver=mytlschallenge&quot;networks: traefik: external: name: traefik_webgateway 但是后端的配置方式折腾了我好几天😭，因为后端是微服务模式，而且我不想增加域名，直接在前端的 url 后面加/api/xxx就能访问到后端服务。最终还是在traefik官网的migration的文章中找到了答案（一开始我怎么也想不到竟然会在迁移教程里找到我想要的内容…），最终配置如下 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455version: &quot;3.7&quot;networks: app: traefik: external: name: traefik_webgatewayservices: comunion-redis: container_name: comunion-back-redis image: redis:alpine restart: always networks: - app # 这里以一个account服务作为示例，其它服务配置基本一致 comunion-account: image: registry.comunion.io/comunion/cos-back-account:dev container_name: comunion-back-account volumes: - /etc/localtime:/etc/localtime env_file: - ./comunion-conf.env environment: PG_MASTER: postgres://xxx:xxx@comunion-db:5432/xxx?sslmode=disable&amp;connect_timeout=10&amp;search_path=comunion&amp;timezone=Asia/Shanghai depends_on: - comunion-redis restart: always networks: - app - traefik labels: - &quot;traefik.enable=true&quot; - &quot;traefik.docker.network=traefik_webgateway&quot; - &quot;traefik.http.services.comunion-account.loadbalancer.server.port=80&quot; # 先添加PathPrefix - &quot;traefik.http.routers.comunion-account.rule=Host(`dev.${SERVER_DOMAIN}`) &amp;&amp; PathPrefix(`/api/account`)&quot; - &quot;traefik.http.routers.comunion-account.entrypoints=websecure&quot; - &quot;traefik.http.routers.comunion-account.tls.certresolver=mytlschallenge&quot; # 再通过stripprefix去掉传递到容器服务的url前缀 - &quot;traefik.http.routers.comunion-account.middlewares=api-account-stripprefix&quot; - &quot;traefik.http.middlewares.api-account-stripprefix.stripprefix.prefixes=/api/account&quot; comunion-db: image: postgres:10.3-alpine container_name: comunion-back-db networks: - app volumes: - ./data/postgres:/var/lib/postgresql/data environment: - POSTGRES_USER=xxx - POSTGRES_PASSWORD=xxx - POSTGRES_DB=xxx 流程跑通 前端代码 merge 到master分支，触发Github actions，开始构建、打包镜像，上传到仓库，ssh连接并拉取最新镜像，重新跑docker容器，完成后发送微信通知。 后端代码 merge 到master分支，触发Github actions，开始构建、打包镜像，上传到仓库，ssh连接并拉取最新镜像，重新跑docker容器，完成后发送微信通知。 完美！😏 最后 🔗 前端仓库地址 🔗 后端仓库地址","link":"/comunion-dev-ci-cd.html"},{"title":"工作中遇到的cookie知识整理","text":"本文主要记录在工作中遇到的cookie知识的一些整理，这些零散的细节的知识点在没遇到的时候是模棱两可，遇到的时候又不是很深入地了解，所以还要查资料，写demo来反复验证。所以这里把这次关于cookie的知识记录下以便后续查看。 在介绍结果之前先阐述个基本知识：同源，即相同协议、相同域名、相同端口。浏览器对于跨域访问有一些限制，但是对于cookie的限制稍微有些不同。 在实验中我们不讨论设置cookie的domain域，只考虑设置path字段，有如下结论： 同源情况下共享cookie，没毛病 不同协议、同域名、同端口在不设置path或使用默认的path=/的情况下是共享cookie的，注意这里的默认path是/，此时http和https是可以共享的 同协议、同域名、不同端口在不设置path或使用默认的path=/的情况下是共享cookie的，此时跨端口是可以共享的 不同协议、同域名、不同端口在不设置path或使用默认的path=/的情况下是共享cookie的，此时跨端口是可以共享的 同协议、同域名、同端口、不同子目录的情况下在不设置path或使用默认的path=/的情况下是共享cookie的，即http://xxx.xx:port/abc和http://xxx.xx:port/def是共享cookie的 同协议、同域名、同端口、不同子目录的情况下在设置path为子目录的情况下不同的子目录是不共享cookie的，即path=/abc时http://xxx.xx:port/abc和http://xxx.xx:port/def不共享 同协议、同域名、不同端口、不同子目录的情况下在不设置path或使用默认的path=/的情况下是共享cookie的，即http://xxx.xx:port1/abc和http://xxx.xx:port2/def是共享cookie的 同协议、不同二级域名在不修改domain的情况下是不共享cookie的，即https://super.domain.com与https://sub.domain.com是不共享cookie的 因此可以得出： 不管使用哪个协议（HTTP/HTTPS）或端口号，浏览器都允许给定的域以及其任何子域名(sub-domains)来访问cookie。 但跨二级域名是不共享cookie的。 测试文件 测试参考 相关文章 RFC 6265 浏览器的同源策略 浏览器同源政策及其规避方法（文章中关于cookie限制这块有误）","link":"/cookie-tidy.html"},{"title":"Windows下调试平板设备","text":"本文主要记录Android上的Chrome和IOS上的Safari浏览器的调试方法，方便以后查看。开始之前请自备梯子，下面会需要翻墙。 Android设备调试 借助于Chrome的inspect工具，我们可以调试Android中使用了WebView的应用，所以调试Chrome网页也是同样的道理。 安装ADB和驱动。网上有很多这方面的文章介绍，但是鉴于很多时候会出现各种问题，所以建议使用一键工具统一安装，下载地址，需翻墙。 安装时一路Y确认安装，结束后你的系统中就已经有了ADB环境和Android驱动。 USB连接上平板设备，并勾选平板设置里面的USB调试(一般在开发者选项里，如果没有开发者选项点击关于并连续点击版本号)，如果平板弹出调试授权窗口，勾选一律允许然后点击确定。 打开命令行输入adb devices，此时应该能获取到设备ID，如果没有请上网查找解决方案。 平板上打开Chrome并输入网址，打开后在PC的Chrome上输入chrome://inspect/#devices，此时可以查看到已连接的平板上打开的网址，点击对应网址下的inspect，此时就会弹出一个调试窗口，这时候你就可以像调试WEB页面一样愉快地调试Android网页了。 IOS设备的调试 IOS上Safari浏览器的调试就比较简单，连接上设备和Mac，打开Mac上的Safari，勾选Safari的偏好设置里高级菜单下的“在菜单栏显示&quot;开发&quot;菜单”。 然后点击PC Safari的&quot;开发&quot;-&gt;&quot;XXX的Mac&quot;下的具体网址，此时就可以在弹出的窗口中进行调试了。 其它环境的调试 至于其它不能调试的情况，都可以使用weinre等方案进行调试，具体请Google之。","link":"/debug-pad.html"},{"title":"记录在开发electron-ssr过程中遇到的问题","text":"首先是项目介绍，其实这个项目就是给shadowsocksr-python项目加一个GUI壳，所以它的功能就是为了FQ。GitHub地址在这 其次，本文这里只记录这此在2017年底开始的重构经历，因为之前的代码写得实在比较乱（我一开始只是打算练习用的。。。）。OK，话不多说，下面进入正题。 脚手架 我们在开发一个完整的功能的时候往往不是从零开始做（因为那太费时间和经历了，还得自己维护项目框架），这里我是从electron-vue项目初始化而来的。为什么用这个框架？跨平台用electron，前端开发用vue配合webpack，所以就选择了这个框架咯。 开发前的约定 之前其它分支的代码乱就是因为在开发之前没有做一个好的规划，然后就是哪用到什么就直接写，不方便后期维护和代码阅读。这次在开发之前做了几个简单的约定： ipc通讯的channel要约定清楚，并且用常量定义，详见https://github.com/erguotou520/electron-ssr/blob/redesign/docs/EVENT_LIST.md 主进程代码在src/main目录维护，渲染进程代码在src/renderer目录维护，两者通用代码在src/shared目录维护，第三方库在src/lib目录维护 主进程和渲染进程都使用数据驱动开发的方式开发，渲染进程使用vue开发，主进程使用rxjs开发，2个进程间使用ipc进行数据变更通知和更新 主进程和渲染进程代码统一使用ES6语法编写 项目目录结构 有了开发约定好就开始撸码，有些代码是从之前的分支中复制过来稍作改变便可，而大部分则是全新编写。src目录的大致结构如下： 1234567891011121314151617181920212223242526272829303132src├─lib│ ├─proxy_conf_helper # mac os上用于设置系统代理模式的helper│ └─sysproxy.exe # windows上用于设置系统代理模式的helper├─main # main进程│ ├─bootstrap.js # 项目启动，初始化操作│ ├─client.js # shadowsocksr-python命令执行和终止│ ├─data.js # main进程的中央数据文件│ ├─index.dev.js # 开发环境的入口文件│ ├─index.js # 入口文件│ ├─ipc.js # 负责ipc通讯│ ├─logger.js # 日志│ ├─pac.js # 负责pac文件下载和提供pac地址│ ├─proxy.js # 设置系统代理模式│ ├─tray-handler.js # 任务栏操作方法│ ├─tray.js # 任务栏│ └─window.js # 页面窗口├─renderer # renderer进程│ ├─assets # 页面资源│ ├─components # vue组件│ ├─qrcode # 二维码识别│ ├─store # renderer进程的中央数据│ ├─views # 页面│ ├─ipc.js # 负责ipc通讯│ ├─constants.js # 常量定义│ └─main.js # 前端入口文件└─shared # main和renderer共享文件夹 ├─config.js # 应用配置相关 ├─env.js # 应用环境相关 ├─events.js # ipc交互事件定义集合 ├─ssr.js # SSR配置对象 └─utils.js # 工具集 renderer进程开发技术点 页面开发中用到了vue vuex 和iview组件库，其中iview稍微做了些修改。 vuex作为前端数据中心，维护了很多页面数据，页面的修改都是维护vuex的state。 鉴于页面内容不是特别多就没有使用vue-router，而是使用简单的component配置is属性做页面切换。 整个页面开发中最饶人的是我把扁平的configs数组变成了按分组显示的树形结构，导致整个交互变得极其复杂，最后在绕来绕去饶了好几次后还是使用数据驱动开发的思维解决。 main进程开发技术点 由于main进程使用rxjs作为数据维护中心，而我又是第一次使用rxjs，所以在初期就遇到了不少问题。比如多处文件可能会触发（ipc和tray都会触发）数据变更，应该怎么去编写和改变Observable数据，比如支持多播以及和renderer进程保持同步。最后还是在data.js中统一初始化和改变数据（对外暴露可改变数据的方法）并提供多播能力，其它文件在使用时直接subscribe关注，在变更时使用data.js暴露的入口进行数据变更。这样在开发时数据的维护会更方便，而且可以保持每个文件尽量只关注自己的业务。 main进程最复杂的应该是设置系统代理功能。由于每个系统的调用方法不一致，所以要收集所有系统的实现方式，可以参考https://github.com/erguotou520/electron-ssr/blob/redesign/docs/AUTO_PROXY.md的收集结果（Linux系统中非gnome桌面如何实现还没有找到方法，如果你知道，欢迎提issue告知）。 理论知道了只是第一步，实现是第二步。开开心心地用child_process.exec执行命令，开发时一切正常，happy。然而到了打包的时候懵逼了，没有可执行文件了。OK，我放到static目录下，还是不行，因为这些文件还是在asar压缩包里，没法复制和执行。最后在electron-builder中找到了extraFiles字段，就是用来将文件复制到项目根目录下的（如何找到项目根目录也是个坑，得使用app.getPaht(‘exe’)来实现`）。 目前还有一个问题也是mac上实现最大的问题。mac上使用networksetup设置需要sudo权限，而如何实现只弹框输入一次管理员密码就可以一直修改系统代理模式才是最大的难题。一开始使用networksetup命令实现时每次切换都需要输入密码，很烦。后来参考shadowsocks-NG项目，直接将它生成的proxy_conf_helper文件复制到项目里使用，~~但目前在打包后还是会闪退，目前仍在查找实现方案。~~然后使用sudo-prompt模块执行sudo命令将其拷贝到指定位置并赋权。 在打包到0.2.0-beta-1版本之前一直使用正常，忽然有人跟我说10.9.5版本的mac闪退，远程调试后才发现原来shadowsocks-NG的proxy_conf_helper不支持10.11以下版本，尴尬。目前最简单的方法就是检查mac版本，然后低于10.11版本的直接屏蔽切换代理的功能，当然有没有更优雅的实现方式还是有待继续思考的。 还有个有意思的问题是在0.2.0-alpha-4版本时提的issue。后来我重新查看了下NodeJs文档，发现确实用execFile更佳，因为它不是在shell中执行，避免了命令被特殊字符（比如&amp;|&quot;'等等）干扰的问题，这个问题倒是也让我学到了些开发经验。 一开始在开发PAC功能时考虑的是这个版本先按简单的来，满足最基本的pac功能即可，而且自己一般都是用chrome插件来选择性的FQ，所以开发完也没太测试。然后打版发布后有用户提BUG说PAC功能用不了，然后自己本地试了下啊，确实用不了（之前蜜汁自信了）。然后找原因啊，还求助了别人啊，愣是没发现哪里的错。一个偶然的情况下重新看到PAC原理才想起来我返回的pac内容里面根本没有指定socks地址和端口啊！后来想了想，因为ssr是要用一些特殊字段做标记然后使用运行时的变量来替换特殊字段的（简单的说就是pac.replace(/__PROXY__/g, 'socks5 127.0.0.1:1080')），这才明白错在哪，原来真相竟然就是这么简单，害我一开始还在那研究http服务器的问题。 其它的坑 配置向下兼容。如果再后期维护时添加了新的系统配置项，需要在系统初始化时复制到应用配置对象中并保存。 异常处理。错误文件？端口占用？ 在更新订阅服务器时，同时使用window.fetch和electron.net.request来请求数据，并使用Promise.race来选择最快完成的数据。 mac系统打包后默认不能复制粘贴，需要添加Menu菜单和常见的一些菜单项来修复该问题。 最后 如果你喜欢这个项目，欢迎来star。如果你觉得这个项目对你有帮助，欢迎来打赏。","link":"/develop-electron-ssr.html"},{"title":"利用dokku打造自己的私有云仓库和自动化部署","text":"dokku是什么？一句话概括就是一个几百行shell代码的高可扩展性的类Heroku的单服务器PAAS平台，利用它可以简化很多docker操作，更加方便我们维护一个docker driven的平台。 创建机器，选择Ubuntu系统，同时做好域名映射 安装dokku 12wget https://raw.githubusercontent.com/dokku/dokku/v0.14.5/bootstrap.shsudo DOKKU_TAG=v0.14.5 bash bootstrap.sh 然后打开对应的域名，完成dokku的初始化 3. 创建gogs应用，参照https://dokku.github.io/tutorials/deploying-gogs-to-dokku 其中推送代码部分可以用tag部署方式，所有命令如下 1234567891011121314151617dokku apps:create gogs# 设置域名dokku domains:add gogs gogs.erguotou.me# 端口映射dokku proxy:ports-add gogs http:80:3000dokku docker-options:add gogs deploy -p 2222:22mkdir -p /var/lib/dokku/data/storage/gogschown -R dokku:dokku /var/lib/dokku/data/storage/gogsdokku storage:mount gogs /var/lib/dokku/data/storage/gogs:/data# 如果选择用mysql作为gogs数据库需要执行下面这些dokku plugin:install https://github.com/dokku/dokku-mysql.git mysqldokku mysql:create gogsdokku mysql:link gogs gogs# 使用指定版本docker pull gogs/gogsdocker tag gogs/gogs dokku/gogsdokku tags:deploy gogs 使用Let’s Encrypt进行https加密 1234sudo dokku plugin:install https://github.com/dokku/dokku-letsencrypt.gitdokku config:set --global DOKKU_LETSENCRYPT_EMAIL=erguotou525@gmail.comdokku letsencrypt gogsdokku letsencrypt:cron-job --add 完成之后打开web页面完成gogs的install，注意配置页面的各设置（mysql的配置地址可以用dokku mysql:info gogs查看。即使设置错了，也可以后期使用dokku enter gogs，在/data/gogs/conf/app.ini中直接修改），其中SSH 端口号填2222，HTTP 端口号填3000，。 5. 创建drone应用，drone分server端和agent端 12345678910111213141516171819202122232425262728293031323334353637383940# serverexport RPC_SECRET=09asudjfkqwn41u2389ahnoqwjn123dokku apps:create drone# 设置域名dokku domains:add drone drone.erguotou.medokku proxy:ports-add drone http:80:80 https:443:80# 这里同样适用sqlite作为数据库# dokku mysql:create drone# dokku mysql:link drone drone## 暂时不能使用最新版本，坑了很久# docker pull drone/drone:latestdocker pull drone/dronedocker tag drone/drone dokku/dronedokku storage:mount drone /var/run/docker.sock:/var/run/docker.sockmkdir -p /var/lib/dokku/data/storage/dronechown -R dokku:dokku /var/lib/dokku/data/storage/dronedokku storage:mount drone /var/lib/dokku/data/storage/drone:/data# 配置drone的环境变量dokku config:set drone DRONE_GOGS_SERVER=https://gogs.erguotou.me DRONE_GIT_ALWAYS_AUTH=true DRONE_RUNNER_CAPACITY=1 DRONE_SERVER_PROTO=https DRONE_SERVER_HOST=drone.erguotou.me DRONE_RPC_SECRET=$RPC_SECRET# dokku config:set drone DRONE_OPEN=false DRONE_GOGS_PRIVATE_MODE=true DRONE_DATABASE_DRIVER=mysql DRONE_DATABASE_DATASOURCE='root:password@tcp(1.2.3.4:3306)/drone?parseTime=true' DRONE_HOST=https://drone.erguotou.me DRONE_GOGS=true DRONE_GOGS_URL=https://gogs.erguotou.me DRONE_SECRET=secret DRONE_ADMIN=username,passworddokku tags:deploy drone# dokku proxy:ports-add drone http:80:8000# dokku proxy:ports-remove drone http:443:443 http:8000:8000 http:80:80dokku letsencrypt drone# agentdokku apps:create drone-agentdokku storage:mount drone-agent /var/run/docker.sock:/var/run/docker.sockdokku config:set drone-agent DRONE_RPC_SERVER=https://drone.erguotou.me DRONE_RPC_SECRET=$RPC_SECRETdocker pull drone/agentdocker tag drone/agent dokku/drone-agentdokku tags:deploy drone-agent## agent，暂时不能使用最新版，直接使用docker命令启动，看最新版源码里/ws/broker请求都没有了# dokku apps:create drone-agent# docker pull drone/agent:latest# docker tag drone/agent:latest dokku/drone-agent:latest# docker run -d -e DRONE_SERVER=wss://drone.erguotou.me/ws/broker -e DRONE_SECRET=password -e DRONE_TIMEOUT=15m -v /var/run/docker.sock:/var/run/docker.sock --restart=always --name=drone-agent-docker drone/drone:0.7.3 agent# 配置agent的环境变量# dokku config:set drone-agent DRONE_SERVER=wss://drone.erguotou.me/ws/broker DRONE_SECRET=secret# dokku storage:mount drone-agent /var/run/docker.sock:/var/run/docker.sock# dokku tags:deploy drone-agent latest 检查应用运行情况 可使用的命令 123456dokku proxy:report appdokku proxy:ports-remove app http:80:3000dokku proxy:ports-add app http:80:3000cat /home/dokku/app/nginx.confdokku ps:stop appdokku ps:start app 创建自己的应用 在dokku中创建对应的app dokku apps:create gift，完成域名映射，配置proxy:ports，使用Let's encrypt插件进行https加密，这些步骤就不多说了。接着在gogs中创建对应的一个仓库，记得项目根目录下要有一个.drone.yml文件（参考https://docs.drone.io/user-guide/进行配置），然后提交代码。 自动发布应用 CD可以有很多种方法，具体还得根据部署环境决定。可以直接用drone中现有的插件去实现也可以自己去开发drone的插件。下面记录的是以前的骚操作完成的项目部署方案。 上一步只能使用drone进行自动构建，要想将构建后的项目自动打包发布，还需要一些额外的操作（这里也是坑了自己好久，主要难题是如何将drone agent生成的文件发布到dokku git里，后来经人提醒可以通过共享ssh的方式，然后后续的共享ssh的操作也是摸索了好久才成功，可谓一路心酸）。 找1台虚机生成一份新的ssh公私钥对（也可以本地备份原来的，然后重新生成）1ssh-keygen -t rsa -C &quot;dokku-deploy&quot; 将上一步生成的id_rsa.pub上传至服务器并添加到dokku中1234# localscp ~/.ssh/id_rsa.pub root@erguotou.me:/root/deploy.pub# serverdokku ssh-keys:add deploy ./deploy.pub 项目根目录新建一个ssh目录，然后将上一步生成的ssh公私钥复制进去1cp ~/.ssh/id_rsa* ./ssh 修改原来的.drone.yml，在原来build之后添加一些操作12345678910111213141516- rm -rf ~/.ssh- mkdir -p ~/.ssh- cp ssh/* ~/.ssh- chmod 600 ~/.ssh/id_rsa # 特别要注意这3行- chmod 644 ~/.ssh/id_rsa.pub- ssh-keyscan erguotou.me &gt;&gt; ~/.ssh/known_hosts- ssh-keyscan 45.77.42.201 &gt;&gt; ~/.ssh/known_hosts- echo 'FROM ilyasemenov/dokku-static-site' &gt; dist/Dockerfile # 根据自己的项目选择合适的Dockerfile或者实现适合自己项目的Dockerfile，也可以使用buildpacks- cd dist- git config --global user.email &quot;erguotou525@gmail.com&quot;- git config --global user.name &quot;erguotou&quot;- git init- git add ./ -A- git commit -m &quot;auto build&quot;- git remote add dokku dokku@erguotou.me:gift- git push -u dokku master --force 至此就完成了自动化部署的工作，现在就可以访问https://gift.erguotou.me了。","link":"/dokku_ci_cd.html"},{"title":"Electron应用开发总结","text":"这次又是工作总结，不过是关于Electron的，之前工作花了差不多10个月做的产品，一直想写个填坑记录的，现在闲下来可以写写了。我们的产品是互联网化的，所以有很多内容也是没做过，一路也是遇到了很多坑。 1.0版本 之前虽然有做过Electron的经历，但之前做的功能相对简单，前端一套东西就可以搞完，但这次不行了。第一个版本当时是用electron-vue模板生成的，在完成产品基本功能后发行的1.0版本中，我们发现了大量的问题，比如 内存占用过大，软件用的时间越长越大，越来越卡。 从主界面打开子页面窗口时会出现很长时间的白屏，用户可能接受不了。 数据库（一开始用的是RxDB）一旦存储大量数据，读取起来就会很卡。 总之给用户的感受就是慢卡白屏。 然后就是开始填坑啊，一个一个来。 内存占用大，没办法Electron应用本身就比较耗内存，Windows版一上来开4个线程，再加上业务代码用到一些类库，所以内存消耗肯定不小。问题的关键是软件用时越长越卡，这个足足消耗了我几个星期去处理。一开始就发现是因为内存泄露的问题，而我自己也没太接触过内存泄露排查这块（自己之前写的代码印象中就没遇到过泄露，再加上自己对常见的泄露的可能性都做了规避），所以光排查问题就花了很长时间。对照网上提供的一些常见可能性都做了排除，学着如何去排查，感觉那段时间真的学到了不少东西啊。最后在别人的指导下找到问题是出在RxDB身上，过程的艰辛就不提了，这是我提的issue地址。 问题是找到了，但是怎么解决呢？等待RxDB修复需要时间，而自己找到的手动gc()的方法似乎也不那么奏效，后来没办法，只有和其它一些问题一起重新开发1.1版本。 打开子页面会白屏这是必然的，因为新开一个窗口加载也需要时间，完成Vue的初始化、业务初始化也需要一段时间，那么这段时间注定是白屏，即使我可以在一开始加一个动画，但肯定还是会有一段白屏时间。而且由于打开多窗口，所以资源的消耗肯定也会增加，内存消耗也会上去。由于当时子窗口和主窗口用的是一个前端模板，所以要加初始化动画还不是那么简单，所以这个问题也就搁置了，加入到1.1版本中一起修复，而修复的方法就是主功能的页面不再单独打开子窗口，只有部分额外功能才会去新开且子窗口和主窗口使用2个不同的模板，减少子窗口渲染时间。 鉴于之前的开发经验，前端使用文档性数据库是主流，且更符合前端知识栈，但如果文档中有的字段内容特别多，那么读取大量数据比如会占用大量内存造成卡顿的情况。如果要解决这个问题需要使用支持只筛选某些字段的文档性数据库或者使用关系型数据库。和上一条结论一样，在1.1版本中更换数据库。 1.1版本 鉴于之前种种问题，用户抱怨不断，老板跟后催促修改，所以只得重新开发一套，在选型的时候就针对上面的问题重新定义开发栈。 项目结构模板，之前使用electron-vue项目生成，但是有些内容相对较老且那时vue-cli 3刚好稳定，意识到这以后必然是趋势，所以就决定用它去初始化了。但cli生成的只是前端项目，所以又找到了vue-cli-plugin-electron-builder插件去完成剩下的初始化内容。后来想想还挺冒险的，毕竟当时vue-cli-plugin-electron-builder还只是alpha版本。 前端还是Vue一套，后端还是NodeJs一套，这个肯定不会改变。 数据库调研了很多，基本上文档性数据库都被pass，而关系型数据库只有sqlite可选，其它非嵌入式的数据库也都不考虑了。但我自己对于关系型数据库的查询已经忘得差不多了，可好在我们开发组有后端同学，所以后续的很多查询都是找他们帮忙的。另外关于sqlite数据库其实应该做一层加密，sqlite本身不支持加密，但有插件可以实现，然后后来因为懒还是没做。还有一点，如果使用关系型数据库，那么数据库初始化是在main进程做呢还是在renderer进程做呢？从业务角度来说最终我肯定是要在renderer进程里调用db方法的。我一开始是打算在main进程做的，这样从逻辑上更符合数据库的定位，然后试过通过global暴露给renderer进程调用，但是这样在序列化的过程中会破坏db原有方法，也考虑过通过ipc，但是如此大量的通讯代价肯定也是很高。一开始没考虑在renderer进程做的另一个考虑是如果在子窗口初始化那么子窗口如何获取这个db实例呢？不过后来发现自己想多了，数据库可以多连接啊，而且我们的应用基本很少会出现多窗口同时写的问题，怕个啥，renderer进程搞起。sqlite确定后我们还需要一个orm库，我们使用的是sequelize，后来发现还有typeorm，但我们的项目不是基于ts的，所以相对来说也不太适合。但sequelize搭配上webpack有个坑就是你必须得把它的所有驱动都装上，很坑（测试使用window.require()方式引入也不行，也许有更好的方案？）。 关于多窗口问题，和设计师保持沟通，改掉以前的交互模式，尽量在一个窗口完成常用操作，部分少见操作可以以子窗口打开，这样内存的消耗也会有所改善。 其它优化包括按需加载，延时加载等。 组件开发 拿到UI给出的界面，在完成基础架构后就开始准备基础组件开发了，我不喜欢用现成的UI框架，一来Electron中使用的是Chromium内核渲染，不存在兼容性问题，可以放心地使用各种新特性，二来自己有洁癖，希望组件层级尽量少，很多UI为了实现更复杂的功能，DOM层级一般较多，而DOM多对渲染本身也是有影响的。组件开发大致有3种： 基础组件，即与业务没有关联性，通过props和event提供各种接口，常见的有按钮、输入框、单选框等表单相关、弹框、警告框、确认框等。这些组件放在components或者ui目录下，组件统一以Ui或者自定义的单词开头，方便识别。 业务组件。一般由基础组件构成，可以使用vuex种的数据。比如窗体按钮（由基础窗体按钮和业务关来）、个人信息组件（由头像和用户名等信息组成）、用户详情信息（由弹框和一些交互按钮组成）等。这些组件放在modules或者widgets目录下，组件统一由M或者W开头。 页面组件，即单个UI页面，可以拆分成多个小组件，最后合并成一个大组件。这些组件放在views或者pages目录下，子组件放在对应业务的子目录下，组件统一由V或者P开头。 严格来说组件开发完都要写测试用例，但我们没时间和精力弄这个，只能在开发的过程种测试功能。组件尽量使用原生标签，尽量减少DOM层级，props可以多开放些，方便后续业务需要。 除了组件完，其它常有的directives、filters、utils也可以在初期就加上，有时间的可以把这些通用的单独出来放到npm里方便以后继续使用。 业务开发 在我们完成组件开发后，页面实现起来就很快了，就像拼乐高玩具一样。当时我开发1.1版本时APP端已经在做新功能了，而我除了要把以前的功能都实现了，还要赶上他们的进度把新功能也给做上，这确实给了我很大压力。不过好在我们这种开发模式相对原生来说会快上很多，花了大概1个半月的时间完成了1.0版本的大部分内容，再花差不多1个月多一点的时间赶上了他们，后续的业务开发相比原生来说就轻松些。这得益于前端混合开发的便利性以及Vue组件化开发的快速性。 原生模块 我想很多人被拦截在Electron之外的一个原因是各种报错，我想装个sqlite3存下数据，结果各种错误，按网上找的各种教程和方法都没用。问题还是出在原生模块上，像sqlite3这种模块是需要在本地进行编译的，它们依赖当前的系统环境，而大多数人在编译这块就过不去了。 我的方法比较简单，首先得安装各个系统必备的编译工具，比如windows需要安装windows-build-tools。直接跳过文档中说的electron-rebuild而是使用electron-builder在postinstall中执行electron-builder install-app-deps，然后你的命令行最好是FQ的，可以直接访问谷歌的那种，后面就正常安装原生模块就可以了，也不需要设置什么npmrc。 原生模块多了每次安装新依赖都需要重新build一遍（也许是我设置问题，可以跳过？）也挺麻烦的，所以有些功能能用js去做的都会用js去实现。 主题系统 我们的应用支持主题切换，在前端更换主题应该是个常见的需求，但这次我想做点不同的，既然我都是Chromium了，那就试下css的新特性:root吧。把我们需要和主题关联的颜色、字体、文字大小等都放到:root中，然后在使用的地方直接写成prop: var(--someVariable)即可。这么做的好处一来原生支持，二来可以统一变量，重复利用，甚至以后可以用cssnext的特性去做颜色值计算等。 随着业务的增多，新的页面也越来越多，需要增加的颜色值也越来越多，因而我们的主题文件中定义的:root里的变量也越来越多，到后来发现新增一个主题需要更改大量的颜色，而且还要调到各种页面各种业务状态下去看页面颜色是否正常。当时就想，这也不是个事啊，这以后要是加主题还不得累死我啊，能不能搞个工具，然后直接让设计师去调色，调好之后直接生成主题包文件呢？当然可以，说做就做，搞个子窗口，显示当前主题中的各种变量，显示它们的颜色并可以手动修改或者选择关联某个变量，并且要实现子窗口修改主窗口实时预览的效果。再加上可以设置主题图片，主题名，主题预览图等信息就OK拉，最后页面大致长这样： 因为主题中要设置的变量特别多，而且每次调整可能都要看下效果，所以设计师让我加了中途保存，下次打开自动应用的功能防止做了一半丢了。加了一个变量搜索，因为实在太多了。 不足的点及可优化的方向 变量仍然很多，有些特殊业务还需要特定条件才能显示，而这种页面调试起来就很麻烦了，理想的方法应该是可以模拟各种环境直接查看某些页面或者输出页面渲染图到文件。 子窗口的实时预览有点麻烦，需要在主窗口变量变动时通知所有的子窗口也去改变，而且自定义主题这个子窗口还不能受影响，否则整个调色过程会很难受，目前还没有做这块。 自定义主题应该以插件的形式导入到应用中，这样真实用户就没有该模块而且不会打包到项目中去，现在只是单纯的通过if (process.env.NODE_ENV !== 'production') {}来做区分。 自动更新 其它 数据存储 非npm得第三方库 本地备份 在线判断 快捷键 api签名 本地字体 webview获取信息 数据库升级 埋点统计 worker线程 数据格式转换 数据同步 自定义窗体 bug跟踪 证书签名 现有问题 数据统计 内容丢失","link":"/electron-app-summary.html"},{"title":"解决Optinal chaining会报no-unused-exceptions的错误","text":"问题起源 在使用vue-cli生成的项目中可以直接使用可选链(Optional chaining)的写法，如this.foo?.bar?.[0]?.()。但是有时候会报一个no-unused-exceptions的错误，eslint认为你这写法仅仅是一个表达式而不是函数调用。一开始就1/2处的时候就直接eslint-disable-next-line忽略掉，但是多了后就在想不能老这么办啊，于是就上网搜索解决方法。 解决方法 最终在这里看到解决方法，禁用eslint的no-unused-expressions规则，改为使用babel的babel/no-unused-expressions规则。应该是eslint默认的规则还没有跟上时代，那babel就说我来替你处理吧。也许以后eslint升级了就可以不需要这么写了。","link":"/eslint-optional-chaining-unused.html"},{"title":"Ghost开发之API","text":"Ghost API 接口 当前版本为0.5.8，后续更新的API不在其中。 本文写作时用的是英文版，下面所有涉及language为en_US的对应的中文版为zh_CN。 下面所有的链接都是以http://your.blog.site:port开头，请注意。 你可以使用Chrome的Postman工具进行调试 登录认证 POST /ghost/api/v0.1/authentication/token ACCEPT json DATA 123456{ grant_type:password username:your.email@email.com(请替换为你的邮箱) password:your_password(请替换为你的登录密码) client_id:ghost-admin} RESULT 1234567{ access_token: 'xxx', expires_in: 3600, refresh_token: 'xxx', token_type: &quot;Bearer&quot;}注意保存返回的结果 如果登录错误，会返回错误结果 1234{ status: 404 errors[0]: {message: 'xxx', type: 'xxxError'}} 错误主要分为不存在的邮箱、错误的密码、密码输入错误次数过多几种 注意：以下所有请求涉及用户权限的，都需要在HTTP请求的头中加入access_token的信息，请求格式为 12Request Headers中添加Authorization: Bearer your_access_token 如果验证信息过期，会提示错误，如果没有加Authorization的头信息也会返回类似的错误信息 获取登录者信息 GET /ghost/api/v0.1/users/me/?status=all&amp;include=roles ACCEPT json Authorization 见上说明 RESULT 1234567891011121314151617181920212223{ accessibility: null bio: null cover: null created_at: &quot;2015-02-08T12:11:34.683Z&quot; created_by: 1 email: &quot;your.email@email.com&quot; id: 1 image: null language: &quot;en_US&quot; last_login: &quot;2015-03-18T08:55:30.330Z&quot; location: null meta_description: null meta_title: null name: &quot;你的名字&quot; roles: [{id: 4, uuid: &quot;9227adb4-a836-4f6c-ba41-7d5dd307968a&quot;, name: &quot;Owner&quot;, description: &quot;Blog Owner&quot;,…}] slug: &quot;your-slug&quot; status: &quot;active&quot; updated_at: &quot;2015-03-18T08:55:30.331Z&quot; updated_by: 1 uuid: &quot;xxxx-uuid&quot; website: null} 每个字段对应的意思从单词应该可以看出来，具体不做说明，注意保存返回结果 下面列出的所有api路径都是由/ghost/api/v0.1开头，在调用时请自行追加 配置相关 系统级的配置信息的json格式 1234{ &quot;key&quot;: &quot;fileStorage&quot;, &quot;value&quot;: true} GET /configuration 获取博客配置信息 GET /configuration/:key 根据指定ID获取配置信息 文章相关 新增文章的业务流程应该是(2,3步骤在Ghost中是监测输入间隔，然后发送请求) 获取标签等信息/tags/?limit=all 输入title后调用/slugs/post/:inputed-title会返回一个新的slug 输入正文时保存/posts/?include=tags，其中发送的数据格式为 12345678910111213141516171819202122232425262728293031{ posts: [ { title: 'xxx', slug: 'xxx', // 上一步获取到的slug markdown: 'xxx', // 输入的markdown内容 image: 'xxx', // 文章的封面 featured: false, // 是否推荐 page: false, //是否单独页 status: &quot;draft&quot;, // 状态为草稿或者发布published language: &quot;en_US&quot;, // 语言 meta_title: null, // 设置里面的meta信息，下同 meta_description: null, author: &quot;1&quot;, // 作者id published_by: null, // 发布者 tags:[ // 标签数组 { description: null hidden: false image: null meta_description: null meta_title: null name: &quot;tag1&quot; post_count: null slug: null // 这个是新增的tag，没有uuid和slug uuid: null } ] } ]} 此请求返回的数据里面有一个id，保存id，下次在保存文章时的地址就是/posts/:id?include=tags 文章的json结构体如下 1234567891011121314151617181920212223{ slug: &quot;welcome-to-ghost&quot;, // 类似文章的链接 status: &quot;published&quot;, // 文章的状态 草稿 已发布等 id: 1, // 文章ID uuid: &quot;xxxx-xxxx&quot;, // 文章的UUID title: &quot;Welcome to Ghost&quot;, // 文章标题 markdown: xxx // 文章的markdown内容 html: xxx // 文章的html内容 image: null, // 图片 featured: false, // 推荐 page: false, // 单独页 language: &quot;en_US&quot;, // 语言 meta_title: null, // meta里面的title meta_description: null, // meta里面的description，下面的很好理解，不做解释 created_at: &quot;2015-02-08T12:11:20.645Z&quot;, created_by: 1, updated_at: &quot;2015-02-08T12:11:20.645Z&quot;, updated_by: 1, published_at: &quot;2015-02-08T12:11:20.684Z&quot;, published_by: 1, author: 1, url: &quot;/welcome-to-ghost/&quot;} GET /posts 获取所有文章，返回的数据里面还包含分页信息 POST /posts 新增文章 GET /posts/:id 根据ID获取文章 GET /posts/slug/:slug 根据文章链接获取文章 PUT /posts/:id 编辑文章 DEL /posts/:id 根据ID删除文章 设置相关 博客的设置数据的json格式 123456789101112131415161718192021222324252627282930313233343536{ &quot;settings&quot;: [ { &quot;id&quot;: 5, &quot;uuid&quot;: &quot;xxxx-xxxx&quot;, &quot;key&quot;: &quot;title&quot;, &quot;value&quot;: &quot;My blog&quot;, &quot;type&quot;: &quot;blog&quot;, &quot;created_at&quot;: &quot;2015-02-08T12:11:35.040Z&quot;, &quot;created_by&quot;: 1, &quot;updated_at&quot;: &quot;2015-03-18T09:47:42.464Z&quot;, &quot;updated_by&quot;: 1 }, ... { &quot;key&quot;: &quot;availableThemes&quot;, // 可用的主题 &quot;value&quot;: [ { &quot;name&quot;: &quot;casper&quot;, &quot;package&quot;: { &quot;name&quot;: &quot;Casper&quot;, &quot;version&quot;: &quot;1.1.5&quot; }, &quot;active&quot;: true } ], &quot;type&quot;: &quot;theme&quot; }, { &quot;key&quot;: &quot;availableApps&quot;, // 可用的app，当前版本暂时还不支持app的调用？ &quot;value&quot;: [], &quot;type&quot;: &quot;app&quot; } ], &quot;meta&quot;: {}} GET /settings 获取所有设置 GET /settings/:key 根据指定key获取设置 PUT /settings 修改设置 用户相关 用户数据的json格式 12345678910111213141516171819202122{ email: &quot;your.email@email.com&quot;, id: 1, uuid: &quot;xxxx-xxxx&quot;, name: &quot;你的名字&quot;, slug: &quot;exxx&quot;, // slug，个人信息页面链接为http://your.blog.site/author/:slug image: null, // 头像 cover: null, // 封面 bio: null, // 简介 website: null, location: null, accessibility: null, // 这是虾米？ status: &quot;active&quot;, language: &quot;en_US&quot;, meta_title: null, meta_description: null, last_login: &quot;2015-03-18T10:11:18.753Z&quot;, created_at: &quot;2015-02-08T12:11:34.683Z&quot;, created_by: 1, updated_at: &quot;2015-03-18T10:11:18.753Z&quot;, updated_by: 1} GET /users 获取所有用户 GET /users/:id 根据指定Id获取用户 GET /users/slug/:slug 根据用户的slug获取用户 GET /users/email/:email 根据邮箱获取用户 PUT /users/password 修改用户登录密码 PUT /users/owner 修改用户的所有者(不懂，没测试过) PUT /users/:id 根据用户id来修改用户信息 POST /users 添加用户 del /users/:id 删除用户 标签相关 标签数据的json格式 12345678910111213141516{ &quot;id&quot;: 1, &quot;uuid&quot;: &quot;xxxx-xxxx&quot;, &quot;name&quot;: &quot;Getting Started&quot;, &quot;slug&quot;: &quot;getting-started&quot;, &quot;description&quot;: null, &quot;image&quot;: null, &quot;hidden&quot;: false, &quot;meta_title&quot;: null, &quot;meta_description&quot;: null, &quot;created_at&quot;: &quot;2015-02-08T12:11:20.685Z&quot;, &quot;created_by&quot;: 1, &quot;updated_at&quot;: &quot;2015-02-08T12:11:20.685Z&quot;, &quot;updated_by&quot;: 1, &quot;parent&quot;: null} GET /tags 获取所有表情 GET /tags/:id 根据Id获取标签 POST /tags 添加标签 PUT /tags/:id 根据ID修改标签 del /tags/:id 根据ID删除标签 角色相关 角色数据的json格式 12345678910{ &quot;id&quot;: 1, &quot;uuid&quot;: &quot;1b925c9f-92f2-45b3-9828-9244adbaaddc&quot;, &quot;name&quot;: &quot;Administrator&quot;, &quot;description&quot;: &quot;Administrators&quot;, &quot;created_at&quot;: &quot;2015-02-08T12:11:20.687Z&quot;, &quot;created_by&quot;: 1, &quot;updated_at&quot;: &quot;2015-02-08T12:11:20.687Z&quot;, &quot;updated_by&quot;: 1} GET /roles/ 获取所有的角色 Slugs GET /slugs/:type/:name 未研究，不做解释 主题 主题数据的json格式 123456{ &quot;uuid&quot;: &quot;casper&quot;, &quot;name&quot;: &quot;Casper&quot;, &quot;version&quot;: &quot;1.1.5&quot;, &quot;active&quot;: true} GET /themes 获取所有主题 PUT /themes/:name 修改当前的主题 通知相关 通知信息的json结构 12345678910{ notifications: [ { dismissible： true, location: 'bottom', type': 'info', // 错误等级'error', 'success', 'warn' and 'info' message: 'message' } ]} GET /notifications POST /notifications del /notifications/:id DB数据库 能获得数据里的各种数据，建议不要直接操作，使用其它方法单独操作 GET /db POST /db del /db 邮件 未测试 POST /mail 发送邮件 POST /mail/test 发送测试邮件 用户认证 未测试。。 POST /authentication/passwordreset PUT /authentication/passwordreset POST /authentication/invitation GET /authentication/invitation POST /authentication/setup GET /authentication/setup POST /authentication/token POST /authentication/revoke 上传文件 POST /uploads uploadimage file数据，上传时的图片文件","link":"/ghost-api.html"},{"title":"Ghost源码解读系列（一）目录结构","text":"本系列文章以Ghost0.5.8安装版本为基础，后续版本升级时可能会做升级记录日志 由于个人水平和理解有限，可能部分地方没有给出分析或者解读有误，欢迎指正 Ghost目录结构 12345678910111213141516171819202122232425262728├content: 内容 ├apps: 以后Ghost开发的app会放在这个目录下，期待吧！ ├data: 数据文件夹，请勿修改此文件下任何内容，默认sqlite数据文件会存放与此 ├images: 图片文件夹，默认使用本地存储时，上传的图片会存于此处 ├themes: 主题文件夹，所有的主题文件夹存放于此，下面以默认的casper主题为例 ├casper: 默认主题 ├assets: 资源目录，不做更多介绍 ├partials: author.hbs: 作者页面 default.hbs: index.hbs: 首页 page.hbs: post.hbs: tag.hbs:├core: 核心模块 ├built: 用Grunt合并压缩后的js代码，不做展开介绍 ├client: 客户端代码，主要是js css font image等内容，后续详细介绍 ├server: 服务端代码，后续详细介绍 ├shared: 共享文件 index.js: 服务器启动入口文件.bower.json: bower文件配置.config.example.js: 示例的配置文件Gruntfile.js: grunt配置index.js: 主入口函数，启动函数位置LICENSE: LICENSEpackage.json: 项目配置PRIVACY.md: 隐私控制，可用的第三方功能说明，可以在config.js中修改README.md: 项目说明文档","link":"/ghost-code-1.html"},{"title":"群友博文大合集","text":"(function() { var bloggers = [ { \"name\": \"hellojammy\", \"avater\": \"http://\"+\"hello1010.com/content/images/2015/01/0-1.jpg\", \"tags\": [\"移动开发\", \"Web前端开发\", \"微信公众号开发\", \"ASP.NET\", \"软件架构设计\"], \"site\": \"http://\"+\"hello1010.com/\" }, { \"name\": \"二锅头\", \"avater\": \"http://\"+\"blog.erguotou.me/content/images/2015/01/baili.png\", \"tags\": [\"WEB前端\", \"杂记\"], \"site\": \"http://\"+\"blog.erguotou.me/\" },{ \"name\": \"WINDISCO\", \"avater\": \"http://\"+\"windisco.qiniudn.com/avatar_03.jpg\", \"tags\": [\"iOS开发\", \"算法\", \"游戏\"], \"site\": \"http://\"+\"windisco.com/\" },{ \"name\": \"iFriskit Pro\", \"avater\": \"http://\"+\"friskit-blog.qiniudn.com/b/32/aa62b93378a96475bc81927f19cfa.png\", \"tags\": [\"算法\", \"机器学习与深度学习\", \"各种开发etc\"], \"site\": \"http://\"+\"friskit.me/\" },{ \"name\": \"蒋佳李\", \"avater\": \"http://\"+\"www.9ute.com/content/images/2015/01/jiangjiali.png\", \"tags\": [\"音乐创作\", \"录音制作\", \"技术\"], \"site\": \"http://\"+\"www.9ute.com/\" },{ \"name\": \"神楽坂立华\", \"avater\": \"http://\"+\"www.moecloud.org/content/images/2015/06/images-1.jpg\", \"tags\": [\"平面设计\", \"DIY\", \"电子爱好者\"], \"site\": \"http://\"+\"www.moecloud.org/\" },{ \"name\": \"anly_zhang\", \"avater\": \"http://\"+\"www.anlyblog.org/content/images/touxiang.jpg\", \"tags\": [\"oracle\", \"数据库\", \"dba\"], \"site\": \"http://\"+\"www.anlyblog.org/\" }, /**{ \"name\": \"萌萌兔\", \"avater\": \"http://\"+\"blog.cuterabbit.cn/content/images/2015/01/color.png\", \"tags\": [\"儿童智能\", \"定位手表\"], \"site\": \"http://\"+\"blog.cuterabbit.cn/\" }, */ { \"name\": \"duwei\", \"avater\": \"http://\"+\"mimg.127.net/p/js6/lib/img/noface.gif\", \"tags\": [\"web前端\"], \"site\": \"http://\"+\"www.blog123.cc/\" },{ \"name\": \"Mido\", \"avater\": \"http://\"+\"i.imoe.moe/images/avatar.jpg\", \"tags\": [\"程序\", \"前端\"], \"site\": \"http://\"+\"imoe.moe/\" },{ \"name\": \"Patrick\", \"avater\": \"http://\"+\"dev2patrick.com/content/images/2015/07/head-2.png\", \"tags\": [\"Android\", \"iOS\", \"开发\"], \"site\": \"http://\"+\"dev2patrick.com/\" },{ \"name\": \"Cho\", \"avater\": \"http://\"+\"mimg.127.net/p/js6/lib/img/noface.gif\", \"tags\": [\"DIY\", \"电子爱好者\"], \"site\": \"http://\"+\"www.znotes.info/\" },{ \"name\": \"乐道\", \"avater\": \"http://\"+\"hujunr.com/content/images/2015/02/logo.png\", \"tags\": [\"杂文\"], \"site\": \"http://\"+\"hujunr.com/\" },{ \"name\": \"伯翎飞云\", \"avater\": \"http://\"+\"jpiq.com/content/images/2015/03/8.gif\", \"tags\": [\"杂文\"], \"site\": \"http://\"+\"jpiq.com/\" },{ \"name\": \"君赏原创\", \"avater\": \"http://\"+\"mimg.127.net/p/js6/lib/img/noface.gif\", \"tags\": [\"paintcode\",\"ios开发\"], \"site\": \"http://\"+\"www.uiapple.com/\" },{ \"name\": \"歪歪羊\", \"avater\": \"http://\"+\"www.yysheep.com/content/images/2015/03/QQ--20150308193614.png\", \"tags\": [\"Java相关\",\"互联网金融\"], \"site\": \"http://\"+\"www.yysheep.com/\" },{ \"name\": \"颜值颇低\", \"avater\": \"http://\"+\"weblib.duapp.com/myicon.png\", \"tags\": [\"WEB研究\"], \"site\": \"http://\"+\"webnn.cn/\" },{ \"name\": \"诺步网\", \"avater\": \"http://\"+\"mimg.127.net/p/js6/lib/img/noface.gif\", \"tags\": [\"drupal\",\"前端\",\"PhoneGap\",\"微信开发\"], \"site\": \"http://\"+\"nuobu.net/\" },{ \"name\": \"谭勇\", \"avater\": \"http://\"+\"mimg.127.net/p/js6/lib/img/noface.gif\", \"tags\": [\"杂文\"], \"site\": \"http://\"+\"charstale.coding.io/\" },{ \"name\": \"言肆\", \"avater\": \"https://\"+\"suki.im/content/images/2015/06/momo1.png\", \"tags\": [\"WEB开发\", \"Android\", \"服务器运维\"], \"site\": \"https://\"+\"suki.im/\" },{ \"name\": \"Cheney\", \"avater\": \"http://\"+\"www.yangchengyu.net/content/images/2015/04/---1.jpg\", \"tags\": [\"iOS开发\", \"Python开发\"], \"site\": \"http://\"+\"www.yangchengyu.net/\" }/*,{ \"name\": \"pican\", \"avater\": \"http://\"+\"www.ipican.com/content/images/2015/05/default-1.jpeg\", \"tags\": [\"iOS开发\",\"PHP开发\",\"摄影\"], \"site\": \"http://\"+\"www.ipican.com/\" },{ \"name\": \"绿叶\", \"avater\": \"http://\"+\"www.lv-ye.com/content/images/2015/05/tx.png\", \"tags\": [\"WEB开发\",\"程序\"], \"site\": \"http://\"+\"www.lv-ye.com/\" }*/,{ \"name\": \"董卓瑶\", \"avater\": \"http://\"+\"dongzhuoyao.com/content/images/2015/07/avatar.jpg\", \"tags\": [\"php框架源码分析\", \"分布式\", \"大数据\"], \"site\": \"http://\"+\"dongzhuoyao.com/\" },{ \"name\": \"MengBo' Li Blog\", \"avater\": \"http://\"+\"imdst.com/content/images/2015/05/3.jpg\", \"tags\": [\"Linux\", \"unix\", \"mysql\", \"python/shell\", \"运维技术分享\"], \"site\": \"http://\"+\"imdst.com/\" },{ \"name\": \"Dream\", \"avater\": \"http://\"+\"q.qlogo.cn/qqapp/100229475/099CEF1841F448A7701E3908AE046B40/100\", \"tags\": [\"运维\", \"专注自动化\"], \"site\": \"http://\"+\"www.thedream.pub/\" },{ \"name\": \"漫步禅意\", \"avater\": \"http://\"+\"ds.cdncache.org/avatar-50/527/99892.jpg\", \"tags\": [\"架构设计\",\"产品经理\", \"程序员\"], \"site\": \"http://\"+\"cocojog.com/\" },{ \"name\": \"Starriv\", \"avater\": \"http://\"+\"mimg.127.net/p/js6/lib/img/noface.gif\", \"tags\": [\"前端\", \"后端\"], \"site\": \"http://\"+\"www.starriv.com\" },{ \"name\": \"石古子\", \"avater\": \"http://\"+\"blog.cytbond.cn/content/images/2015/07/QQ--20150706143009-1.jpg\", \"tags\": [\"技术分享\", \"Linux\"], \"site\": \"http://\"+\"blog.cytbond.cn/\" },{ \"name\": \"云卷(juàn)云书\", \"avater\": \"http://\"+\"kingyf.com/content/images/2015/08/63879-1.png\", \"tags\": [\"信息安全\", \"Web服务\", \"团队管理\", \"前端技术\", \"Java开发\"], \"site\": \"http://\"+\"kingyf.com/\" } ]; var tempStr = ''; var t1 = setInterval(function(){ if (typeof jQuery !== \"undefined\") { clearInterval(t1); var js = document.createElement('script'); js.type= 'text/javascript'; js.src= \"http://\"+\"cdn.bootcss.com/jquery.isotope/2.0.0/isotope.pkgd.min.js\"; document.getElementsByTagName('body')[0].appendChild(js); js.onload = function(){ $(function() { var $container = $('#bloggers'); $container.isotope({ itemSelector: '.blogger', masonry: { isFitWidth :true } }); for (var i = 0; i < bloggers.length; i++) { var $t = $(tempStr); $t.children('img').attr('src', bloggers[i].avater).next('h5').text(bloggers[i].name).next('tag').text(bloggers[i].tags.join(',')).next('a').attr('href', bloggers[i].site).html(bloggers[i].site); $container.isotope('insert', $t); } }); } } }, 500); })(); .post-template .post-header { text-align: center; } .post-template .post { max-width: none; width: 96%; margin: 0 2%; } #bloggers { margin: 0 auto; } .blogger { position: relative; margin: 10px 8px; width: 280px; box-shadow: 0 0 1px 1px #ccc; display: block; padding: 8px; box-sizing: border-box; float: left; } .blogger:hover { box-shadow: 0 0 1px 1px #f60; } .blogger img { position: absolute; left: 8px; top: 8px; padding: 0; border-radius: 50%; width: 40px !important; height: 40px !important; margin: 0 !important; cursor: pointer; transition: all .5s; -moz-transition: all .5s; -webkit-transition: all .5s; -o-transition: all .5s; } .blogger img:hover { transform: rotate(360deg); -ms-transform: rotate(360deg); -webkit-transform: rotate(360deg); -o-transform: rotate(360deg); -moz-transform: rotate(360deg); } .blogger h5 { display: inline-block; margin: 0; border-left: 50px solid transparent; height: 40px; line-height: 40px; text-overflow: ellipsis; overflow: hidden; white-space: nowrap; width: 100%; box-sizing: border-box; } .blogger tag, .blogger a { display: block; margin: 1%; font-size: 14px; line-height: 18px; text-overflow: ellipsis; width: 98%; overflow: hidden; white-space: nowrap; vertical-align: top; } .blogger a { display: inline-block; } .blogger tag:before { content: ''; display: inline-block; background-image: url(data:image/png;base64,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%3D%3D); width: 18px; height: 18px; background-size: 100% 100%; margin-right: 8px; } .blogger a:before { content: ''; display: inline-block; width: 18px; height: 18px; background-size: 100% 100%; margin-right: 8px; background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABIAAAASCAYAAABWzo5XAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAyZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuNS1jMDIxIDc5LjE1NTc3MiwgMjAxNC8wMS8xMy0xOTo0NDowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvIiB4bWxuczp4bXBNTT0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wL21tLyIgeG1sbnM6c3RSZWY9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9zVHlwZS9SZXNvdXJjZVJlZiMiIHhtcDpDcmVhdG9yVG9vbD0iQWRvYmUgUGhvdG9zaG9wIENDIDIwMTQgKFdpbmRvd3MpIiB4bXBNTTpJbnN0YW5jZUlEPSJ4bXAuaWlkOjZFMzkzMDREOUQ0RTExRTRCMEE5OEU4MUE4Q0QxNTZBIiB4bXBNTTpEb2N1bWVudElEPSJ4bXAuZGlkOjZFMzkzMDRFOUQ0RTExRTRCMEE5OEU4MUE4Q0QxNTZBIj4gPHhtcE1NOkRlcml2ZWRGcm9tIHN0UmVmOmluc3RhbmNlSUQ9InhtcC5paWQ6NkUzOTMwNEI5RDRFMTFFNEIwQTk4RTgxQThDRDE1NkEiIHN0UmVmOmRvY3VtZW50SUQ9InhtcC5kaWQ6NkUzOTMwNEM5RDRFMTFFNEIwQTk4RTgxQThDRDE1NkEiLz4gPC9yZGY6RGVzY3JpcHRpb24+IDwvcmRmOlJERj4gPC94OnhtcG1ldGE+IDw/eHBhY2tldCBlbmQ9InIiPz5OMX2LAAABV0lEQVR42pTSzStEURjH8Tneig1FNBvKTmoWSko0ChsLL4kslK1ssLDx0pSYnYVShplZs/E2YsEGf4PssPCy8Q8gub6nnlun23XnmVuf7p157v2d85xzTKz0awm9+MUP9j3Pu6ooIaASO/jGHN7RjZQxpkYbYgfMIR1Sa8VZmTIkgzcsB4u09cTtWRM0JWGpiHeqNUFd2JXnOMbcIuszyq1WE1SOTzTgAO43SSxiTbPQ/RjCCYYDIXdIsE4xE/LhNDpk5GPc4xCXOJcZDmDSHgNCHvwdcVvIynNW2olLO2n5vSEDvGICH8FZVCGPdee/epxiAT3/9W3bsvxZ7WHTqbfgRtakGUfFguw05/GFFadu12gbBRnI0+zKBRoj6rPY0rRWiAhJSotNmiC7xZ0h7/ThFu1R7bhBg7hGm1Mfl5BEsXXxg/wDOYIZvMhRqMMqHjVB9voTYADxfGp9UkgPWgAAAABJRU5ErkJggg%3D%3D); }","link":"/ghost-list.html"},{"title":"在搬瓦工上安装Ghost","text":"前面的内容不做介绍，SSH连接上（本文以CentOS 6 64位系统做说明） 安装需要的环境，中间有确认的过程，直接输入y回车 1yum install libtool automake autoconf gcc-c++ openssl-devel 在/home目录下新建一个目录（名字随意，主要用于存放我们的文件，本例使用的是latazu）latazu，并下载我们需要的文件nodejs、ghost 12345cd /homemkdir latazucd latazuwget http://nodejs.org/dist/v0.10.36/node-v0.10.36.tar.gzwget http://cdn.diancloud.com/ghost/releases/Ghost-0.5.8-zh.zip 编译安装nodejs（make的过程有点长，耐心等待） 1234tar zxvf node-v0.10.36.tar.gzcd node-v0.10.36./configuremake &amp;&amp; make install 解压ghost文件，并配置ghost配置文件config.js 12345cd ../unzip Ghost-0.5.8-zh.zip -d ghostcd ghostcp config.example.js config.jsvi config.js 配置完成后保存（具体配置不做详细说明） 6. 安装依赖文件（只安装生产环境需要的文件） 1npm install --production 如果npm过程中出现glibc版本过低的问题，请参考&quot;libc.so.6: version `GLIBC_2.14’ not found&quot;系统的glibc版本太低升级glibc版本 设置环境变量并启动Ghost（这里使用的是forever守护进程） 123export NODE_ENV=productionnpm install -g foreverforever start index.js 安装Nginx 12rpm -Uvh http://nginx.org/packages/centos/6/noarch/RPMS/nginx-release-centos-6-0.el6.ngx.noarch.rpmyum install nginx 配置nginx（新建一个配置文件ghost.conf，下面有一个样例） 12345678910111213141516171819mkdir /etc/nginx/logsvi /etc/nginx/conf.d/ghost.confserver { listen 80; server_name www.renshiwo.me renshiwo.me; charset utf-8; access_log logs/ghost.log; location / { proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Host $http_host; proxy_set_header X-NginX-Proxy true; proxy_pass http://127.0.0.1:2368; proxy_redirect off; }} 启动nginx，并设置开机自启动 12service start nginxchkconfig nginx on OK!可以了，现在访问你的域名看看吧！哦~对了，不要忘记设置域名解析！ 其它后续操作 1.安装FTP vsftpd的安装配置 2.安装ShandowSocks（翻墙必备） CentOS下shadowsocks一键安装脚本","link":"/ghost-on-banwagong.html"},{"title":"在OpenShift上安装Ghost","text":"使用OpenShift(以下简称OS)搭建Ghost环境的好处就是简单、免费，速度还不错。如果只是希望使用Ghost的用户不妨试试吧。 注册OS并登录 这一步不做介绍，很简单。 创建Ghost 在OS的控制台中切换到Applications页面，点击Add Application。 在搜索输入框中输入ghost并回车，在搜索结果页面中点击Ghost 0.5.10(目前版本)。 在Public URL中输入一个唯一的二级域名，这里输入的内容不重要，后面可以使用自己的域名，其它默认就可以了，点击Create Application。 完成后的页面可以无视，重新点击Applications就可以看到已经创建好的Ghost博客了，点击进去可以看到系统给你分配的二级域名，点击此链接即可访问博客。 使用自定义的域名 在上面第4步的二级域名旁有一个change链接，点击之。 在新页面的Domain name里输入你想要绑定的域名，下面的ssl本文不做介绍，接着点击下面的Save按钮。 最后在你的域名的dns解析的地方加一条cname解析，cname的指向是之前系统给你分配的二级域名。配置好了以后等待一段时间，你就可以用你自定义的域名来访问Ghost博客了。 Ghost汉化与升级 汉化 汉化我采用的是GhostChina提供的汉化版本。 首先去下载页面下载最新的版本。 然后再OS的控制台的应用界面里面找到Source Code。 复制此地址。 使用git拷贝项目 12#xxxxxx是刚复制的地址git clone ssh://xxxxxx 将第1步下载的中文版的/content/themes/casper-zh目录下的所有文件拷贝到第3步clone的项目下的/content/themes/casper目录下并覆盖原文件。将中文版的/core目录下的所有文件拷贝到第3步clone的项目下的/core目录下并覆盖原文件。 在第3步clone的项目的根目录下执行 123git add ./ --allgit commit-m &quot;hanhua&quot;git push 在执行push前请在OS中添加自己电脑的ssh公钥，生成公钥的方法可参考Git SSH Key 生成步骤，OS添加公钥的方法就是点击Settings–&gt;Add a new key，在Key name中输入一个名字，在Paste the contents of your public key file中输入你的公钥并保存。 push完成后系统会自动重启，无需担心重启的问题，完成后再次访问你的域名吧。 升级 升级请参照更新 Ghost","link":"/ghost-on-openshift.html"},{"title":"在树莓派上安装Ghost的一些坑","text":"最近开始玩树莓派，自然要在小pi上装个node，跑个Ghost啊。中途遇到了一些小坑，这里记录一下。 raspbian系统安装后默认只有大概4G左右的空间（可以使用df -hl查看磁盘空间），tf卡的其它空间浪费了，需要扩容到整个tf卡的大小。在raspbian中运行 1sudo raspi-config 选择expand_rootfs，按照提示操作并重启。 删除了一些不需要的安装包。首先安装wajig（这个工具集成了apt-get/dpkg/aptitude等等）： 1sudo apt-get install wajig -y 然后查看已安装的包 1wajig large 找到后面几个用不到的且占用体积较大的删除掉，可一次性删除多个： 1sudo aptitude remove xxxx xxxx xxxx nodejs的sqlite3模块似乎没有arm平台的编译包，我也懒得自己编辑了，直接改成使用mysql了。 其它没什么不一样的，使用pm2守护Ghost，使用Nginx做代理，运行，OK！","link":"/ghost-on-raspberry.html"},{"title":"使用Swiftype完成Ghost搜索功能","text":"不知道出于什么目的，Ghost并没有给出搜索功能，但是我们可以使用第三方服务来完成站内搜索，本文推荐使用Swiftype来实现这一功能（不仅仅说Ghost可以使用该服务，所有需要站内搜索的都可以，可以查看本站blog.erguotou.me体验）。 注册 OK，这一步不做过多介绍，应该都会，记得激活账号，激活后进入控制台主界面。 创建一个搜索引擎 选择左侧的“Create a search engine(standard web crawler)”，然后输入你的Ghost博客地址。接着系统会验证你输入的网址，验证成功后在弹出框中输入引擎名称。 安装搜索引擎 在控制面板中切换至“install”，点击&quot;Start Installation&quot;。在&quot;Appearance&quot;中选择搜索引擎到外貌，这里我选择默认设置一直Next下去，最后点击&quot;Save&amp;Preview&quot;。 然后点击“Install Code”，将代码复制到你的Ghost中去（可以在default.hbs的body标签后面添加），完成后点击Next。 在“Search Field”中根据自己的情况（一般Ghost博客没有搜索输入框）选择，这里我选择第二个“ No, my site needs an input field”，接着选择“Use the Swiftype search tab”，下面会有一个预览样式，然后点击Next。 最后点击页面最下方的“Active Swiftype”就可以为你的Ghost博客提供一个样式不错的搜索引擎啦～","link":"/ghost-swiftype-guide.html"},{"title":"GIT分支管理策略(非Git workflow)","text":"参照 http://www.ruanyifeng.com/blog/2012/07/git.html 主分支Master 主分支有且只有一个，所有提供给用户使用的正式版本都在这个分支上发布。 开发分支Develop 日常的开发工作应该都在这个分支上进行。 1git checkout -b develop 如果需要从develop对外发布版本 12git checkout mastergit merge --no-ff development 注：这里的参数--no-ff是不进行快速合并(快速合并只是改变指针)的意思。 临时分支 前面介绍的是两条主要分支，一般正常情况下仓库中只存在这2个分支，但有时需要一些临时性的分支用于特定目的，这些分支在使用完成后应该删除掉，删除的命令为 1git branch -d temp-branch 如果删除过程中出现错误需要强制删除的话可以执行 1git branch -D temp-branch 注：临时分支不要提交到远程，在本地提交就可以了。 功能分支(feature) 比如突然需要开发某个新的功能，但不是必需的，或者实现起来可能有些困难而直接放弃，或者是BOSS临时的想法，但不确定是否要加入到产品中，此时可以使用功能分支。 1git checkout -b feature-xxx develop 开发完成后需要合并到develop分支的话 12git checkout developgit merge --no-ff feature-xxx 然后删除 预发布分支(release) 当我们需要在正式发布版本前做一个测试的时候就需要预发布分支。使用过程和功能分支稍有差别，第一步创建 1git checkout -b release-xxx develop 然后可能要执行一些操作，比如我会在这时执行grunt构建命令，完成开发代码到发布代码的构建。 当测试完成且没有问题的时候就开始合并代码 1234git checkout mastergit merge --no-ff release-xxx# 对合并后产生的新节点做一个标签(一般为版本号)git tag -a xxx 接着根据情况考虑是否需要合并到开发分支(比如我grunt构建后的代码就不需要)，最后说删除此分支。 修复bug分支 项目正式发布后难免会有bug出现，此时就需要这样的分支，命名为fixbug-xxx，xxx一般是项目的bug管理中对应的bug编号。 1git checkout -b fixbug-xxx master 修改完成后合并到master分支 123456git checkout mastergit merge --no-ff fixbug-xxx# 遵循版本升级原则# 一般bug修复后的版本号在上个版本的最后一位上面加1# 比如上个版本为0.1.0，那么bug修复后的版本就是0.1.1git tag -a xxx 再合并到develop分支 12git checkout developgit merge --no-ff fixbug-xxx 最后删除此分支。","link":"/git-branch-management-strategy.html"},{"title":"Git迁移记录","text":"背景 之前公司的Git服务器是用的Gogs，当时安装时选择的是tidb数据库。后来发现tidb数据库无法使用ssh服务（更改为其它数据库是可以的），但是我们的开发过程中有很多命令行的一些操作，导致每次使用命令时都需要输入用户名和密码，很麻烦，所以想改下数据库，然后使用ssh://格式的Git仓库。 尝试 第一次是打算从Gogs入手，但是Gogs并不提供数据迁移的能力。 后来准备从数据库角度出发，备份之前的数据库和仓库。仓库备份很简单，但是数据库是tidb采用了xorm库封装的，没有启动服务，所以没法用mysql客户端连接。 再后来准备尝试用xorm库提供的方法新建个工程然后把数据备份出来，奈何需要学习Go语言，而且好多不会玩，后来还是没有尝试了。 也找过DBA帮我看下，无果… 现行解决方案 现在采用的解决方案虽然有点麻烦，但好歹也是可行的。首先重新建个Gogs的服务，初始化安装（这次选择的是sqlite，因为那台服务器上没有mysql，也就懒得装了），重新建立组织和空仓库，建用户。然后通过clone之前的仓库并添加新的仓库地址最后push的方式来完成的。理论虽然简单，但中间还是遇到了一些小问题，这里记录下。下面是shell脚本（参考了Push local Git repo to new remote including all branches and tags）。 1234567891011121314151617181920212223242526#!/bin/shsourceProtocal='http://'sourcePrefix='192.168.10.240:3000/'targetPrefix='git@192.168.10.240:'array=( org/repo.git org/repo1.git)for repository in ${array[@]}; do # username是原仓库的用户名，password是原仓库的密码 source=${sourceProtocal}username:password@${sourcePrefix}${repository} target=${targetPrefix}${repository} tmp=${repository##*/} dir=${tmp%.git*} git clone ${source} cd ${dir} git remote add target ${target} for remote in `git branch -r | grep -v master `; do git checkout --track remotes/$remote done # git push target '*:*' git push target --all git push target --tags echo 'source '${source}' clone OK.' cd ../done 添加ssh公钥 ssh公钥是为了让我们和服务器通讯时免去输入用户名和密码的一种认证方式，详细可以查看这篇文章，我们改成ssh方式后需要将我们电脑的公钥上传至Gogs才能实现无需密码的push操作。 1.生成公钥（已经生成过可以跳过）。如果电脑上安装了Git并且有Git Bash，那么可以打开Git Bash运行 12# -C 后面的是注释，可不传ssh-keygen -t rsa -C &quot;youremail@xxx.com&quot; 然后一路回车生成我们的公私钥，文件存放在C:\\Users\\{your windows accoutn}\\.ssh。 如果该方法不适合你请自行百度生成ssh公钥。 2.上传我们的公钥。打开上面说的目录里面的id_rsa.pub文件，复制里面的所有内容。再打开Gogs服务的网址，登陆。 点击右上角头像，选择用户设置，选择管理 SSH 密钥，点击增加密钥。密钥名称处随便填写个，然后在密钥内容中粘贴我们前面复制的内容，点击下面的增加密钥按钮完成添加。 工作副本的仓库地址修改 1.进入原克隆的工作目录 1cd /path/to/your/workspace 2.查看原工作副本的远程地址 1git remote -v 可以看到之前的地址是以http://开头的，我们需要修改其为新的ssh://方式。 3.修改地址 1git remote set-url origin &lt;git@192.168.10.240:org/repo.git&gt; org和repo为上述git remote -v查看得到的组织名和仓库名，该地址也可以通过网页上复制得到 。 一切OK！ 如果有其它非origin远程，可以通过同样的方法修改仓库地址。","link":"/git-migration.html"},{"title":"利用firebase打造极速静态博客","text":"之前博客一直是做的动态的，后台页面，添加博文，然后保存后查看博文。但最近VPS感觉不稳定加之价格有点小高（主要是穷），打算将vps上的所有东西都放在云端，使用免费资源（还不是因为穷）。第一步就是从博客开始。 Hexo介绍 Hexo是由台湾的一名大学生创建的静态博客系统，它基于’NodeJs’，生成文章的速度非常快，这也是为什么选择它的原因。当然还有很多其它的系统，但是作为NodeJs阵营的我当然是选择它啦。 Hexo项目搭建 首先，安装官方文档过一遍，在本地安装搭建一个Hexo项目，例如我的HexoBlog。 这时运行hexo server并打开浏览器访问http://localhost:4000应该就可以访问到你搭建后的博客了，如果没有，请仔细阅读文档，重来一遍。 这里我稍微修改了下_config.yml文件，然后添加了deploy模块 1234deploy: type: git repo: https://github.com/erguotou520/HexoBlog.git branch: gh-pages 这样以后deploy后的public文件夹里的内容会自动提交到gh-pages分支下。 数据迁移 最开始的博客是在Ghost上跑的，后来又是用的pagekit，到现在的Hexo，每次数据迁移都是手动复制粘贴，太麻烦了，即使它们可能提供了一些迁移工具，但是还是会存在不靠谱的情况，所以还是手动复制吧。 这里要提到Hexo的一个好处了，文章是以markdown格式的文件存储，而不是存在数据库中，对于我们是可视的，再配合上后面的git，可以实现文章的历史管理。 结合Github 本地环境搭建好了之前就开始将它推送到github了，为什么放在github？一来是有个存储的地方，二来自带历史版本管理，三来可以实现自动化。 首先，添加hexo的git deploy插件。 1npm install hexo-deployer-git --save 接着在项目中添加一些必要的文件，因为Hexo的生成器并没有生成这些文件和内容。 添加.gitignore，把node_modules和.deploy_git添加进来，后者是在添加hexo-deployer-git插件并执行hexo deploy命令时会生成。 补充package.json文件，可以加上description等其它字段，可选 添加README.md说明文件，可选 OK，完成后开始推送。这个时候已经实现了hexo和github的结合，但是现在，每次添加完文章后都需要手动执行hexo generate和hexo deploy，是否可以更简单呢？ 与Travis结合 我们可以利用TravisCI的自动化测试来进行自动构建任务。网上也有很多介绍Hexo+Github的文章，简单来说，就是在项目根目录下添加.travis.yml，内容如下 12345678910111213141516171819202122232425262728language: node_jsnode_js: - &quot;6&quot;branches: only: - masterbefore_install: - npm install hexo-cli -g - git config --global push.default matching - git config --global user.name &quot;erguotou&quot; - git config --global user.email &quot;erguotou525@gmail.com&quot; - sed -i'' &quot;/^ *repo/s~github\\.com~${ACCESS_TOKEN}@github.com~&quot; _config.ymlinstall: - npm installscript: # - git submodule init # 用于更新主题 # - git submodule update - hexo clean - hexo d -gcache: directories: - node_modules 其中{ACCESS_TOKEN}就是下文要介绍的token。 接着在github中生成一个用于自动提交用的token。点击github中头像–&gt;‘Settings’–&gt;Personal access tokens–&gt;Generate new token生成一个给travis用的token（权限我只勾选了repo相关的）。 因为github提供了中使用token进行push的方式，这也是我为什么_config.yml文件中deploy模块用的repo是https地址的原因了。 生成token后将其添加到travis的环境变量中ACCESS_TOKEN=token。 最后提交所有文件，等待TravisCI的构建结果，此时应当完成了与TravisCI结合的功能，如果构建报错，请具体结合报错内容修改。 与Firebase结合 说到现在，我们都还没提到我们的主角Firebase。对于还不了解Firebase的同学建议先去看下网上的介绍。Firebase为我们提供了实时的云端存储和并提供全球CDN服务，我就是要利用它的CDN服务将我们的静态博客挂在CDN上。 首先，全局安装它的cli工具 1npm install -g firebase-tools 然后登录firebase 123# 不带参数会登录报错# 如遇到翻墙问题请自行解决firebase login --no-localhost 接着进入项目根目录，执行 1firebase init 安装提示完成初始化，Firebase会自动在项目根目录下创建firebase.json文件，我们保证firebase.json里的public值为public即可，因为public文件夹是hexo生成的博客的目录。 12345{ &quot;hosting&quot;: { &quot;public&quot;: &quot;public&quot; }} 此时执行firebase deploy就可以将我们的博客推送上去了。但是我们需要结合TravisCI实现自动部署，所以在.travis.yml中添加firebase的自动部署模块 123# 2017-07-10更新after_success: - firebase deploy --non-interactive --token ${FIREBASE_TOKEN} 其中FIREBASE_TOKEN是让TravisCI进行部署时的密钥，它需要我们通过下面的命令来生成 1firebase login:ci --no-localhost 登录验证成功后会得到一个token，复制它，在travis中添加环境变量FIREBASE_TOKEN，value为刚复制的token。 最后git提交推送，travis自动构建，firebase自动部署，OK，完美。 Firebase自定义域名 默认firebase会为我们提供一个域名访问地址，但我们一般会用自己的域名来访问。此时按照Firebase Hosting的文档提示，在我们的域名中添加2个txt记录完成域名拥有权的验证，验证完成后等待firebase颁发https证书（我睡了一晚，醒来之后就好了），最后按照提示，将我们自己的域名做一个cname，解析到firebase给我们提供的域名上就可以啦。 总结 本文介绍了Hexo+Github+TravisCI+Firebase搭建一个免费的拥有https的全球cdn加速的静态博客，综合利用了现有的网上资源，整个搭建过程会遇到各种问题，但都被一一解决。当然，Hexo作为静态博客，也会有一些不足，但这些不足我们都可以使用插件系统来实现，这也是后面要做的内容。 后面打算利用Firebase的database功能实现一个简单的博客评论系统，然后是定义一个自己用的主题，默认的太难看啦。后面的还有很长的一段路要走呢～","link":"/hexo-on-firebase.html"},{"title":"我的首个硬件开发","text":"故事背景 人到30，岁月的痕迹就会在身上体现出来。老婆大人一直很在意她的颈纹，说很难看（我倒是没有很在意啦😅），然后刷小红书看到颈纹治疗仪，看了下价格动辄上千，有的有2 3千，而且效果怎么样也不是很清楚。然后跟我说了这个事，也让我看下原理啥的。 经过一番调查，发现红光（波长720纳米左右）对于胶原蛋白确实有一定的促进左右，现在也有医院有专门的红光治疗，但是要排队，收费也不便宜。顺便说下搜索到的信息里也提到蓝光对于治疗痔疮有一定效果。而胶原蛋白在一些文章里也提到确实对于治疗颈纹有一定的效果。但是如果想完全靠这种方式治疗颈纹也是不可能的，更多的应该靠日常的行为（少低头玩手机📵）来规避，不过作为一种辅助治疗方法每天坚持下去应该还是有少许效果的（起码对于心理上有很大的提升作用，心美了人才美😄）。 先看最终效果 制作手法非常简陋，请将就😜。 前期准备 迫于昂贵的费用（穷），我决定还是自己来做一个吧。本来我自己对于动手类的手作就蛮有兴趣的，正好趁机也可以购入我人生的第一台3D打印机😍。这是我第一次真正意义上做和硬件有关的东西，之前的都是玩玩。于是我开始了疯狂购物的时间，总共买了这些东西： AnyCubic Mega S FDM 3D打印机和PLA耗材 STM32F103C8T6 最小系统开发板一个（事后了解到也许AtTiny 85是个更小的实现方案，不过还需要Arduino板子来做上传器，以后有机会再试试吧） 200mAh的锂电池3节（我已经不记得怎么计算电功率了😅，凭感觉买的，事后证明200mAh大概能用4-5次的样子吧） 锂电池充电模块2个（用来给锂电池充电，虽然锂电池带了充电保护模块，但是方便使用。不过买回来发现买的是Micro USB的口，家里差点没有这种USB线，应该买Mini USB的，相关知识准备不足） 电阻包一份（实际用的是47欧姆的电阻，也是不清楚用多大的电阻合适，凭感觉的😅） 红光LED 二极管若干（只要是补库存，之前的都用掉了） 开关（其实开关也买错了😭，买成了按下去会弹上来的那种一次性reset按钮，应该买自锁开关的） 电烙铁套装（电烙铁一直不太会保养，之前的2个30W的都不好用了，这次换了可调功率的黄花电烙铁，用着趁手一些） 其它库存小零件，包括杜邦线、铜线、无源蜂鸣器、皮筋以及蓝丁胶 那在开始之前，我们先定义自己的产品名称就叫做“DIY颈纹理疗仪”吧（好土🤣），以下简称理疗仪。 开工之3D列印 鉴于以前自学过一些3D建模的知识便自信满满的开始了理疗仪的3D设计，然后被现实各种打脸。我比较喜欢那种简单的，上手就能用的软件，所以一开始就用的 TinkerCad，但是它更偏向于简单应用，对于复杂点的就不太适用，而且转动操作很难受。第一次用它设计了一个打印出来后发现尺寸不对，而且转动结构也有问题，原件在这，大概是这样： 后来我就开始重新搜索好用的3D设计工具，solidworks算很常用的工业设计工具了，但是Mac电脑上没法用，最终投入了onshape的怀抱，作为一款在线设计工具，支持中文，界面也算简洁，找了几个视频学习了下也就开始上手了。其实3D设计也是常用形状/路径+各种布尔运算，和2D设计没有太多本质上的差别（个人理解，请轻喷）。在熬了几个夜后做出了第二版，原件在这，大概是这样的： 这次对转轴结构做了修改，对尺寸也做了重新计算（事后发现其实有点高了，可以再矮一点），挖了2个孔用来放元件（挖孔这里花费了很多时间，实现的也不是很好）。衔接部分采用一边挖孔，一边沾上一个可以插进去的方式实现。 切片，开机，打印。在经过近一天的打印后发现了一些问题，2边半环在填充方式的实现上不一致，后来查看切片预览发现也确实不一样，不知道为什么，一边合理，一边不太合理，可能是有挖孔的原因。另外因为切片工具默认是有支撑的，所以打印完成后还需要手动去除掉一些支撑，尤其是挖洞的支撑很难去掉，挺麻烦的😞。我就在考虑要不要下次打印的时候去掉支撑，但是不加支撑的话一些悬空打印的地方肯定要出问题，所以还是加上吧。最让我开心的是转轴部分是OK的，我看着打印的时候总感觉要坏，毕竟是悬空的结构，也是吓死我了，如果这个结构再设计大一些应该会好很多。 Emmm～ 忘记拍照了，真实效果直接看成品吧。 电路设计和组装 我在3D打印机到之前就先组装好了LED灯组，直接用的裸铜丝接的，最后通电的时候竟然搞错并联电路的接法，实在惭愧，高中学的知识全都还给老师了😂。总共用了16个（原定20个的）LED发光二极管，用了非常简陋的方式并联起来，用热熔枪固定在一个纸片上，极其简陋和随心。然后用2节1.5V电池驱动用了2天，开关都是直接用铜线接触电池并用胶布裹着的最原始的方式使用的，还经常接触不灵。 后来买的元件陆陆续续到了，我也就开始了电路学习和制作之坑。我是先从锂电池充放电开始的，这个模块说起来应该是最简单，最顺利的了，直接锂电池接充电模块的2个IN接口并公用这2个接口作为输出就可以了。 鉴于开关买错了，只能另辟蹊径，用公母杜邦头的组合来做一个简易的开关，后面还是要买个自锁开关给它换掉。然后插电，测试充放电都OK，LED正常点亮。其实到这一步已经可以用了，但是我还是希望能加个简单的功能，就是10分钟提醒下，20分钟再提醒下。因为我查到的一些文章里也都提到LED照射时间不宜过长，15到20分钟就差不多了。所以我就开始折腾起开发板来了。 对于一个写惯了高级开发语言的程序员来说，写C语言代码还是稍微有那么一些不习惯，但是我们用到的功能也非常简单，都是照着Demo改改，上手还算快。不过这里的难点还是STM32开发板各种资料和IDE混乱，上网搜索发现有各种方式来开发，导致我一头雾水，一会这种方式试试，一会那种方式试试。我最后用的是基于Arduino的方式来开发STM32，但Arduino IDE非常原始，没有提示，没有校验，有哪些库可用，函数功能什么的都没有。后来换用VSCode的PlatformIO插件来开发，但PlatformIO创建项目时又因为网络问题耽误了很久。所以最终就是一会用用这个，一会用用那个，很烦😣。 在测试的时候发现上传（我用的是USB转TTL的方式）也是很头疼的事，经常上传失败，有时又能成功，一直没发现规律，直到我把阵脚焊接固定住才发现之前可能是阵脚接触不良导致的，真是蠢，当时应该买STLink的上传烧录器。 还有我原来想实现一个简单的倒计时，但是搜索后发现delay函数并不精准，想要精确可以用时钟，然而时钟这块我看了N篇文章，每一篇讲的都是非常基础知识，涉及到很多基础概念，什么晶振、预分频、频率计算等等，至今我都没搞明白，试了几个demo也没成功，最终还是放弃了😅，还是选用最蠢的delay累加实现（管它精准不精准，差不多就可以了，20分钟范围内也差不了多少）。 接着是要实现无源蜂鸣器的震动，一开始也是搜索文章，发现很多也是从基础的PWM讲起，实现代码也很复杂啰嗦，看着我就头晕。直到我测试了tone这个函数，发现这TM才是我要的简单库函数啊😘，非常符合我们普通开发者使用，简单、直达效果，之前倒计时要是也能这么简单多好。 最终代码是这样的（我在PlatformIO里写的，去掉第一行直接放到Arduino IDE里应该也可以编译）： 123456789101112131415161718192021222324252627282930313233343536373839404142#include &lt;Arduino.h&gt;int buzzerPin = PB10;int m10 = 10 * 60;int m20 = 20 * 60;int sec = 0;void notify(int times) { long frequency = 300; for (int i = 0; i &lt; times; i++) { tone(buzzerPin, frequency, 500); delay(500); noTone(buzzerPin); delay(500); }}void runTask() { ++sec; delay(1000); // Serial.println(sec); if (sec == m20) { notify(5); // PWR_EnterSTANDBYMode(); __WFI(); } else { if (sec == m10) { notify(1); } runTask(); }}void setup() { // Serial.begin(115200); pinMode(buzzerPin, OUTPUT); runTask();}void loop() {} 总结 最终我们的理疗仪算是实现了，老婆大人也很开心😃，每天美滋滋的挂在脖子上理疗个20分钟，隔个3-4天充一下电就可以了。 对我来说这次制作蛮有意思的，不仅仅是东西做出来了，更多的是学习的过程，现在我也会学习一些物理知识，学习一些焊接技巧，没事再找点3D模型或者自己做一个打印出来玩玩。但我也意识到，对于完全没接触过的领域，靠着自己那薄弱的知识储备必然要踩很多坑，如果有一个引路人会好很多（虽然这次也认识了一个做硬件开发的，但是段位太高，不适合教我，而且人家也很忙，不过提醒了我一句：初学者还是用Arduino开发比较好）。所以在做没接触过的事情前1要多学习多了解，2是找相关领域的人去沟通，把盲点在前期抹掉才能避免后续的坑。","link":"/my-first-hardware-develop.html"},{"title":"记新windows电脑打造前端开发环境流程","text":"系统环境 查看电脑配置（主要是CPU内存硬盘SSD这些），对于该配置能完成什么样的开发强度心里有数 联网，设置固定IP（较推荐） 清理已安装工具，取消不常用的任务栏（比如IE浏览器，应用商店） 规划分区，明确每个分区盘的用处 工具下载 下载以下常用工具并安装 7z Chrome VSCode python Git（VSCode安装后再安装），SourceTree（图形化Git管理），BeyondCompare（Diff对比工具） NodeJs yarn Everything Wox（Everything和python安装后再安装） Cmder Office工具 MacType（美化windows字体显示） 迅雷极速版/FDM/Motrix IM工具 QQ/TIM 微信 钉钉 VirtualBox 其它工具 坚果云 Zerotier-One 从坚果云的同步文件中安装ssr并添加订阅地址 Chrome 前端开发浏览器是重头，所以要配置好浏览器的一些东西 ssr运行后登录chrome同步扩展程序，确保常用的vue-devtool Proxy SwitchSharp NIM(NodeJs调试管理工具) 划词翻译扩展已安装 登录后等待同步书签 为Proxy SwitchSharp导入坚果云同步的备份文件，并点击扩展图标选择自动模式，至此FQ已完成，后续可以科学上网 设置 -&gt; 下载内容 -&gt; 下载前询问每个文件的保存位置 勾选上 Cmder windows下如果要获得流畅的命令行使用体验，Cmder那是必备的工具，后续的命令行操作也是使用该工具执行，安装后需要做一些简单的设置，参考 注册右键菜单 管理员身份打开cmd并cd到Cmder目录，执行Cmder.exe /REGISTER ALL 设置启动目录 Settings -&gt; Startup - &gt; Task，修改{cmd::Cmder}项，把: cmd /k &quot;%ConEmuDir%\\..\\init.bat&quot;改为cmd /k &quot;%ConEmuDir%\\..\\init.bat&quot; -new_console:d:G:\\workspace 设置alias 打开Cmder安装目录下的config/user-aliases.cmd文件，添加常用的简写命令，比如 1gc = git commit -am $1 设置常用快捷键 在Settings -&gt; Keys &amp; Macro页面中搜索split，为split bottom设置快捷键Ctrl+Shift+D为split right设置快捷键Ctrl+D，保持和iTerm2一致。设置Minimize/Restore (Quake-style hotkey also)的快捷键为Ctrl+F1，这个可以用来快速显隐窗口。 Git Git现在几乎成了主流的版本控制工具，在开发之前我们需要先对Git做个简单的配置 配置Git 12git config --global user.name &quot;erguotou&quot;git config --global user.email erguotou525@gmail.com 生成本地公私钥 12ssh-keygen -t rsacat ~/.ssh/id_rsa.pub 将生成的公钥复制到Github/Gitlab之类的仓库中。 修改文件默认结尾格式 12git config core.eol lfgit config core.autocrlf false VSCode 目前来看最火的编辑器，速度比Atom快很多，使用前先安装几个常用的插件 EditorConfig for VS Code ESLint HTML Snippets language-postcss PostCSS syntax language-stylus Path Intellisense Prettier Vetur Beautify 其它如Flutter/Dart/Docker/Docker Compose/DotENV/Python/英汉词典 然后修改创建文件的默认结尾为LF，在用户配置中加入&quot;files.eol&quot;: &quot;\\n&quot; NodeJs 前端开发必备，主要是换源，安装常用全局模块 123npm i -g nrm http-servernrm use taobaoyarn config set registry 'https://registry.npm.taobao.org' Everything &amp; Wox 类似Mac上的Alfred，配置简单，主要是改下快捷键为Ctrl+~ 高级玩法 AutoHotKey AHK为windows用户提供了更多的可能，开发时可以用它定义快捷输入、执行自动化操作，可以定义开机自启动脚本，显隐应用窗口等等 MacType Windows的ClearType字体很多时候看着都很难受，这时我们需要MacType来优化字体显示，可以参考这个做个自定义优化或者直接使用Candy改的MacType 其它 使用ssh-keygen -t rsa生成公私钥，并将公钥上传到Github/Bitbucket/Gitlab等 使用ssh-copy-id -i ~/.ssh/id_rsa.pub user@server.host命令将公钥上传到服务器实现免密登录 开发一段时间后使用到的一些工具 Photoshop CC Cow 本地代理 GifCam 本地录屏并生成gif文件 navcat 数据库连接工具 oss-aliyun 连接阿里OSS 15_Second_ADB_Installer 快速安装adb工具 Android SDK besttrace 路由跟踪工具 charles-proxy/Fiddler 本地请求拦截 网易云音乐 Dism 轻量级windows管理工具 DockerToolbox 没有用Docker for Windows，因为它和VirtualBox冲突 Golang lean cli leancloud命令行工具 Medis redis连接工具 minio 本地oss服务 mingw-w64 mongodb/robo3t mongodb和其连接工具 ngrok 内网穿透工具 postman api测试工具 搜狗输入法 TeamViewer/向日葵 远程连接工具 Telegram TunSafe Vagrant 微信web开发者工具 windirstat 查看本地磁盘占用空间，磁盘清理就靠它定位了 WinSCP 远程连接和管理工具 各种虚拟机镜像 Windows/Ubuntu等","link":"/new-windows-develop-env.html"},{"title":"利用Nginx让IIS和tomcat共用80端口","text":"项目：《安徽省儿童医院》主网站（PHP开发）与微信（JAVA开发）共用服务器 原来整合时使用的是jakarta桥接插件，但当时整合时就各种弄不懂，也是各种迷糊然后就好了，最终主网站用的域名是www.ahetyy.com，微信端用的是211.149.198.47/etyy。 然后网站和微信一直都能使用，相安无事，但有一次莫名其妙地出了问题，不得其解。 在修复时打算按照原来的方式来，可是发现又不会弄了，因为当初怎么弄好的都不记得。 无奈之下在百度搜索时发现一篇《IIS tomcat共用80端口解决一个IP多个域名：使用Nginx反向代理方式使两者兼容》的文章，受其启发，准备改用Nginx来完成。 1.下载 http://nginx.org/en/download.html 我当时下载的是nginx/Windows-1.7.8 版本。 2.解压 3.修改配置 nginx的配置看起来还是比较复杂的，现在的配置只是保证能使用，但不一定是最好的 修改Nginx的conf目录下的nginx.conf文件，修改server的配置如下： server { listen 80; server_name www.ahetyy.com; location ^~ /etyy { proxy_pass http://localhost:8080/etyy; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } location / { proxy_pass http://localhost:81; } } 其中server_name表示对外访问的域名，第一个location的规则是 任意以&quot;/etyy&quot;开头的请求都转发给http://localhost:8080/etyy也就是tomcat来处理，第二个location的规则是其余请求全都发给php的主网站处理。 特别注意：第一个location下的配置中的proxy_set_header的配置是必须的，否则最后打开http://www.ahetyy.com/etyy时页面请求的css和js路径都会是localhost:8080的，因为tomcat那边得到的请求就是localhost:8080的，需要将请求的头信息修改为真实请求的请求路径才行。（但是现在页面的base的路径上会有一个端口80，有点小小强迫症的我就忍了~） 4.运行 cmd切换到nginx.exe的目录下，启动-- start nginx 停止-- nginx -s stop，有时会结束不掉，我就会手动关闭进程~ 5.设置Nginx以服务方式启动 （暂时没做，网上教程看着好复杂- -！），搞定！","link":"/nginx-tomcat-iis.html"},{"title":"NodeJs分享","text":"技术分享以及项目实践 目录 起源 特性 发展 影响 安装 生态圈 项目应用 起源 Nodejs是什么？ 服务器端运行的 Javascript 基于 Google Chrome的javascript engine V8 事件驱动，无阻塞 Evented,no-blocking 扩展js语义：增加了模块化 大约有8000行 c/c++代码，2000行 js 代码 另外这里有一篇在线的文章深入浅出Node.js可以参阅。 特性 支持高并发 异步io 发展 Nodejs版本 在和io.js合并之前一直维持着0.x.x版本，但是和io.js合并后就已经开始是4.x.x，5.x.x甚至6.x.x。 影响 由于js语法简单，掌握起来非常快，且大多数开发者都比较熟悉，所以上手很快。再加上有npm库的支持，使得nodejs开发也是很快，而且是越发展越迅猛的势头。它可以运用于许多场景，不仅仅是web开发，可以做桌面应用，手机App，可以命令行等等。 在web通讯中运用最广的应该是socket.io，它可以应用到web实时通讯，可以用于游戏通讯，可以用于在线开发工具通讯或者热重载等等。 在服务器领域最火的应该是express，用它开发web服务器非常快而且性能不错。 在用户身份认证方面使用最多的应该是passport，它为身份认证提供了统一的接口，支持本地身份认证和各种第三方身份认证。 在桌面应用开发方面有nw.js和electron，相对来说electron更好，而且Github官方出的开发工具Atom就是使用electron开发的。使用它们开发的工具还有很多，包括slack // todo 在手机App方向应用最火的、热度最高的应该算是ionic和React Native，前者借助于Angularjs和PhoneGap可以实现用js开发跨平台的手机应用。后者是Fackbook依赖于其React推出的手机应用开发套件，其火热程度非同一般。 其它更多的产品等你发现和分享。 安装 Nodejs环境的安装方法各平台不一致，但都比较简单。非windows平台建议使用nvm进行nodejs的安装和版本管理。 全局安装模块 使用npm安装全局模块npm install -g some-module 本地安装 使用npm安装本地模块npm install some-module，它有2个常用的参数--save和--save-dev，分别表示将该模块依赖信息保存到package.json的dependencies和devDependencies，分别表示运行时依赖和开发时依赖。这样项目发布出去后别人就可以通过npm install --production和npm install命令将依赖安装上。 安装指定版本或指定tag 安装指定版本 npm install some-module@1.3.0 安装指定tag npm install some-module#dev 更多其它的安装条件在这里不做说明 更新 更新可以直接重新安装也可以使用update命令npm update [-g] some-module 卸载 对应于install命令有uninstall命令，使用方法和install一致npm uninstall [-g] [--save|--save-dev] 一些说明 npm的包大多是嵌套的，即包A依赖包B，包B又依赖包C，npm会处理所有的依赖关系并全部安装（npm 2和npm 3有所区别，npm 2是在每个包下安装其所有的依赖包，包括嵌套依赖，而npm 3会先分析包的依赖关系，将依赖扁平化，减少重复依赖） 由于国内网络管制原因，可能有些包在安装时会出现失败，如果出现失败，建议使用国内npm源，比如cnpm等。个人喜欢使用nrm进行管理 123npm install -g nrmnrm lsnrm use taobao # 这里使用的是淘宝源 生态圈 Nodejs的生态圈主要靠npm(node package manager)。这里面有成千上万的工具，每天更新的包数量就有//todo 当我们需要使用node开发某些功能时要善用npm，因为它里面已经有很多现成的包，不需要我们重复造轮子，直接拿来用就可以了。 我们可以通过npm search或者去npm官网搜索，输入关键词，找到包后查看其说明，如果是我们想要的，那就npm install它吧。 项目应用 此次精总前端项目就大量使用了Nodejs的相关技术。 包安装。使用npm（npm也是很多前端库文件的发布目录，bower等已经不适合现在的趋势）将项目使用的框架文件安装到本地并使用node的文件模块将其复制到我们的项目目录中（多这一步是因为我们没有采用开发时编译的思路，因为这对框架的搭建和开发学习的成本要求较高） gulp任务。使用gulp添加开发时任务gulp dev，包括代码风格检查和预编译语言的实时编译以及浏览器自动重载等。还有其它的包括js文档生成任务和文档查看服务器任务等。 源代码的构建。使用nodejs生态圈中的构建工具对源码进行构建，生成服务发布的目录文件，主要是对代码进行合并压缩和版本控制。","link":"/nodejs-share.html"},{"title":"基于openwrt的家庭网络设置","text":"家里网络终于通了，开始要捣鼓起来了。 让宽带师傅改桥接（究竟有没有效果不知道） openwrt软路由设置pppoe拨号，发现是100开头的内网地址，后面准备申请让电信给公网ip 前往 下载最新版本，上传到软路由，解压并移动到/usr/sbin目录，执行AdGuardHome -s install完成服务安装并启动 前往软路由ip:3000按照引导完成初始配置，dns端口填5335，方便某服务使用。 在设置 - 常规设置中添加上游DNS服务器，最好是dot或doh的，可参考https://lovemen.cc/moe1621.html，测试并应用。 在过滤器 - DNS封锁清单中添加一些常用的过滤规则，如 12345678# Easylist Chinahttps://easylist-downloads.adblockplus.org/easylistchina.txt# 合并自EasylistChina、EasylistLite、CJX'sAnnoyance、EasyPrivacyhttps://gitee.com/halflife/list/raw/master/ad3.txt# 合并自EasylistChina、EasylistLite、CJX'sAnnoyance，并补充了贴吧过滤规则https://gitee.com/halflife/list/raw/master/ad.txt# 大圣净化: 主要针对国内视频网站https://raw.githubusercontent.com/jdlingyu/ad-wars/master/hosts openwrt导出备份文件，/usr/sbin/AdGuradHome.yml文件也复制出来，建一个项目，存储这2个文件并保存，方便下次继续使用。","link":"/openwrt-setup.html"},{"title":"mp4视频实现边下载边播放","text":"在做视频播放时,出现了这样一个问题,就是网页上播放mp4视频时,必须要等到视频下载完成之后,才能播放,不能够随意拖拽,之后通过一个叫做ffmpeg的视频转码软件解决了这个问题. 软件地址:链接: http://pan.baidu.com/s/1qW2ZpJe 密码: 291n windows下进入,通过cmd命令行进入该软件的目录bin文件夹下,然后,输入qt-faststart.exe 源文件.mp4 新文件.mp4 就会当前目录生成一个转过的mp4视频, 最后,视频要通过nginx服务器作为中转来实现在线播放,具体配置如下: nginx服务器的root目录要改为具体的tomcat目录存放转换好了的视频资源路径,端口要改成一个不和tomcat冲突的端口号 jsp视频播放页面,加载视频资源的时候访问的是nginx服务器(通过nginx的端口号来访问)不访问tomcat,访问nginx之后,然后nginx寻找资源从tomcat的静态资源存放路径中去读取事先上传过来的视频,当然如果你愿意把视频直接拷到nginx的默认根目录,也可以不需要改动nginx的conf配置文件的root目录 这里是当时jsp页面端的部分代码,nginx的端口号改的是8080,视频播放插件用的是ckplayer 123456789//nginx服务器视频地址var path=location.protocol+&quot;//&quot;+window.location.host+&quot;:8080&quot;+&quot;${path}&quot;; var flashvars={ f:path, c:0, b:1 };var params={bgcolor:'#FFF',allowFullScreen:true,allowScriptAccess:'always',wmode:'transparent'}; CKobject.embedSWF(&quot;&lt;c:url value='/static/ckplayer6.4/ckplayer/ckplayer.swf'/&gt;&quot;,'a1','ckplayer_a1','800','470',flashvars,params);","link":"/play-video-while-downloading.html"},{"title":"ppt-online","text":"在做科大学生骨干培训班这个项目时 ,由于需要用到在线浏览学生的ppt文件,为了实现这个问题,采用的解决方案是通过一个软件将其转换为flash进行播放. 软件准备:链接:http://pan.baidu.com/s/1sjv5DPb 解压之后,可以看到iSpring Presenter文件夹,iSpring Presenter 是以 PowerPoint 插件的形式工作的，下载解压后先运行 !)iSpringPresenterPortable.exe，选择安装后会自动添加插件，再打开 PowerPoint 就能看到了，支持 Microsoft PowerPoint 2003/2007/2010. 安装完毕之后,打开一个ppt文件,这时ppt菜单工具栏会出现一个iSpring Presenter工具选项,点击切换到该工具选项,点击publish按钮,弹出一个对话框,general选项卡有个Player Template,可以选择一个适合的播放器模板,还有就是选择生成路径,其他选项卡设置可以不动,点击弹出框的按钮publish即可.具体如下图 完了之后生成一个文件,里面有swf文件以及js 和html文件,在实际应用中,把html和js文件写成jsp形式,然后把jsp文件里面引用swf的路径替换为从数据库读取的路径即可. 整个过程就是把ppt转swf文件,然后通过,软件提供的html和js整合一个公共的ppt在线播放页面,用来加载swf文件即可.","link":"/ppt-online.html"},{"title":"优秀Web字体收集","text":"InfoQ 123p: { font-family: 'Lantinghei SC', 'Open Sans', Arial, 'Hiragino Sans GB', 'Microsoft YaHei', 微软雅黑, STHeiti, 'WenQuanYi Micro Hei', SimSun, Helvetica, sans-serif;} Vue.js 123p: { font-family: 'Source Sans Pro', 'Helvetica Neue', Arial, sans-serif;} Source code 123pre: { font-family: &quot;Source Code Pro&quot;, Consolas, Monaco, Menlo, monospace;}","link":"/pretty-webfont.html"},{"title":"搭建一套k3s的集群环境","text":"服务器组织 准备4个服务器，hostname如下 rancher-server k3s-server k3s-agent1 k3s-agent2 其中rancher-server和k3s-server2个节点配置稍微高点，agent节点配置可以低点，1G内存也是够了。 安装 rancher-server上按照rancher官网配置跑起来， 123456789101112131415# docker加速mkdir /etc/dockervi /etc/docker/daemon.json# 填入内容`{ &quot;registry-mirrors&quot;: [ &quot;https://1nj0zren.mirror.aliyuncs.com&quot;, &quot;https://docker.mirrors.ustc.edu.cn&quot;, &quot;http://f1361db2.m.daocloud.io&quot;, &quot;https://registry.docker-cn.com&quot; ]}`# 安装dockercurl -fsSL https://get.docker.com | sh -docker run -d --restart=unless-stopped -p 8080:80 -p 9443:443 rancher/rancher:stable 然后在rancher的web页面上添加集群，选择自定义，复制添加的命令（第2个，因为需要跳过ssl认证的过程）后面备用 2. 在k3s-server节点上执行 12345678910111213141516# 关闭防火墙systemctl stop firewalldsystemctl disable firewalld# latest节点下载不了，需要手动指定版本，否则下载失败# 当前最新版本，可替换export INSTALL_K3S_VERSION=v1.17.3+k3s1# 使用ffp.yux.io提供的代理服务，再次感谢curl -sfL https://ffp.yux.io/r/https://get.k3s.io | sh -# 显示token，复制cat /var/lib/rancher/k3s/server/node-token# 查看当前ip，复制ip addr# 查看host，确认已分配hostname# 在/etc/hosts中添加一条记录是对hostname的解析# 如 127.0.0.1 k3s-server 在k3s-agent2个节点上执行 12345# latest节点下载不了，需要手动指定版本，否则下载失败# 当前最新版本，可替换export INSTALL_K3S_VERSION=v1.17.3+k3s1# 使用ffp.yux.io提供的代理服务，再次感谢curl -sfL https://ffp.yux.io/r/https://get.k3s.io | K3S_URL=https://上一步复制的ip:6443 K3S_TOKEN=上一步复制的token sh - 将第一步复制的集群添加命令在k3s-server节点上执行，等待rancher上面的状态更新，在完成后会变成active状态，此时就表示完成了。 目前就研究到这么多，后续的得结合helm做发布了。","link":"/rancher-k3s.html"},{"title":"基于Rancher搭建k8s的集群环境","text":"本文主要纪录了在k8s的学习过程中我是如何搭建k8s集群环境的经历。 在学习和了解了k8s的一些基础概念我开始尝试去自己搭建一套集群环境，经过一段时间的尝试，我决定使用rancher来帮助搭建环境，并使用rancher os作为主机镜像。 你要问我为什么使用rancher搭建？因为简单啊！为什么使用rancher os作为主机镜像？因为小啊！ 环境准备 官网下载好rancheros.iso文件 4台虚拟机或者主机，根据实际业务场景增加或减少，机器用途如下： Hostname IP Role Configuration rancher-server 192.168.103.90 rancher server 1C1G8G k8s-node1 192.168.103.101 k8s node 2C2G20G k8s-node2 192.168.103.102 k8s node 2C2G20G k8s-node3 192.168.103.103 k8s node 2C2G20G 确认本机已生成ssh密钥对，然后在本机生成cloud-config.yml，用于ssh连接到node节点： 1echo -e &quot;#cloud-config\\nhostname: rancher-server\\nssh_authorized_keys:\\n - $(cat .ssh/id_rsa.pub)&quot; &gt; $HOME/cloud-config.yml 如果虚拟机网络没有dhcp，还需要在cloud-config.yml中加入network相关的配置 1echo -e &quot;#cloud-config\\nhostname: rancher-server\\nrancher:\\n network:\\n interfaces:\\n eth0:\\n address: 192.168.103.90/24\\n gateway: 192.168.103.1\\n mtu: 1500\\n dhcp: false\\nssh_authorized_keys:\\n - $(cat .ssh/id_rsa.pub)&quot; &gt; $HOME/cloud-config.yml PS：一定要保证hostname唯一，\b我之前就被坑了 安装Rancher OS系统 在rancher-server虚机上选择iso镜像，启动虚机，进入系统后启动的是类似Live CD的系统，所以我们需要先安装rancheros到硬盘，否则下次重启后数据都将丢失 使用命令ip addr查看网卡是否被分配ip，如果没有请参考官网介绍配置静态ip 1234sudo ros config set rancher.network.interfaces.eth0.address 192.168.103.90/24sudo ros config set rancher.network.interfaces.eth0.gateway 192.168.103.1sudo ros config set rancher.network.interfaces.eth0.mtu 1500sudo ros config set rancher.network.interfaces.eth0.dhcp false 设置完成后执行sudo system-docker restart network使其生效 给虚机设置password：sudo passwd rancher 将本机的cloud-config.yml文件复制到虚机上：scp $HOME/cloud-config.yml rancher@172.68.1.100:/home/rancher/cloud-config.yml，如果本机可以通过ssh登录那么反向的从虚机上执行scp命令也可以 在虚机上执行安装：sudo ros install -d /dev/sda -c cloud-config.yml，完成后重启虚机 注意：如果使用ros命令设置的网络ip和cloud-config.yml配置的ip是一致的，那么在虚机装好系统后本机将无法ssh连上，因为本机已经存储了该ip对应的公钥，所以需要删除~/.ssh/known_hosts文件中该ip所在行 重新ssh连到虚机，\b切换虚机docker版本，参考切换到支持的版本号，切换命令：sudo ros engine switch docker-17.03.2-ce 重复之前的操作，注意在安装之前要先修改cloud-config.yml文件中的ip地址以及hostname，这样我们就可以得到3台node节点。PS：之前试过克隆虚机的方式，但打开克隆的机器无法登陆，所以还是选择重复执行的方式。 Docker加速 在所有的虚机上执行sudo vi /etc/docker/daemon.json并填入下面内容 123{ &quot;registry-mirrors&quot;: [&quot;https://registry.docker-cn.com&quot;]} 保存后执行sudo system-docker restart docker然后执行docker info查看是否成功设置docker源 安装Rancher server 在rancher-server虚机上执行 1sudo docker run -d --restart=unless-stopped -p 8080:8080 rancher/server:stable 等待一段时间后在本地打开浏览器访问http://&lt;rancher-server-ip&gt;:8080即可访问Rancher UI。 在web页面中的操作就不做详细介绍，大致就是添加环境，然后按照页面提示添加我们的3台k8s node主机，然后等待各种服务安装完成即可，点击查看官方视频介绍（需翻墙） PS：参考文章中kubernetes环境管理一节修改国内加速。","link":"/rancher-k8s.html"},{"title":"闲置树莓派捣腾记","text":"手上有一个树莓派，之前装个openelec看看视频什么的，后来因为一些原因废弃了。本来打算做私有云的，但是树莓派做私有云可能有些力不从心，等安定了后再捣腾私有云吧，到时可能黑群晖，也可能白群晖，也可能其它方案，都还不一定呢。现在先拿来玩耍玩耍做个共享弄个开源ownCloud还是可以的。废话不多说，进入正题。 安装系统 使用SDFormat格掉SD卡。 使用Win32 Disk Imager将img镜像写入SD卡。这2步都在Win主机上执行，因为快，这也是为什么不推荐使用NOOBS安装的原因，太慢了。 卸下SD卡，装在我们的树莓派上，其它电源、网线、键鼠、显示器都接上。键鼠和显示器不是必须，但是有时为了方便会接上，而且刚进入系统用界面看IP地址也比较方便。 开机，点亮。 简单配置。如果是用NOOBS安装的系统，这步可以跳过。进入系统界面后，打开控制台，运行sudo raspi-config进入配置页面。选择第一个Expand Filesystem，将SD卡里的剩余空间全部扩充上。完成后可能要求重启。 调教系统 更新源。参考科大的帮助页。如果需要更新已有软件，可以使用sudo apt-get upgrade。 静态IP。网上关于更改/etc/network/interfaces文件的方法我试了，没用（jessie版本开始不能用此方法了），在界面中也没找到网络设置的位置。不过可以使用这种方法： 123456sudo nano /etc/dhcpcd.conf# 在配置文件最后加上interface eth0static ip_address=192.168.1.200static routers=192.168.1.1static domain_name_servers=114.114.114.114 改完后记得重启下。 3. 安装samba。不知道是因为执行过apt-get upgrade的原因还是什么，在安装时会出现依赖冲突，不能安装的情况。最后参考http://askubuntu.com/questions/222658/samba-installation-failed-on-ubuntu-12-10 里面介绍的方法解决的。首先执行 1sudo apt-get install --fix-broken &amp;&amp; sudo apt-get autoremove &amp;&amp; sudo apt-get update &amp;&amp; sudo apt-get install samba 失败，然后卸载。 1sudo apt-get remove samba-common libwbclient0 tdb-tools`，卸载完成后重新安装`sudo apt-get install samba samba-common-bin 4. 配置samba。参照http://www.dreamxu.com/raspberrypi-nas/ 。先备份配置 1sudo cp /etc/samba/smb.conf /etc/samba/smb.conf.bak 然后修改配置文件sudo vim /etc/samba/smb.conf并删除默认的home共享。 1234567[share] comment = Raspberry smb path = /home/pi/share browseable = yes writeable = yes create mask = 0664 directory mask = 0775 为了简单，此处直接使用已有的pi用户。在/home/pi下新建share目录。完成后重启samba服务sudo service samba restart。到此就完成了samba的安装配置，可以在设备上拷贝文件测试了。","link":"/raspberry-pi-samba.html"},{"title":"前端学习之路","text":"以下只是自己总结的一些经验，欢迎大家讨论并提出自己的意见。 1. 道亦有道 学习任何一门语言，都应该遵循它的编程规范，前端也不例外，一致的代码规范为我们后面的学习和维护会减少很多麻烦。这里介绍几个前端规范文档。 GOOGLE的前端代码规范 编写灵活、稳定、高质量的 HTML 和 CSS 代码的规范。 2. 历史沉淀 在WEB开发中，有许多问题是需要我们解决的，其中比较让人头疼的就是浏览器规范不一，我们需要一个统一的工具来实现多浏览器的通用，而Jquery就是一个不错的实现。对于新人来说，学习Jquery似乎是一个必经之路，只有走过这条路才能发现更好的更适合使用需求的。文档方面首推w3school ，这里有很多新人学习的资料，也是很多人成长道路上的第一份学习资料，建议将“HTML教程”和“浏览器脚本”这2个部分学习好，尤其是“JQuery”这部分，还有一个JQuery的API。 同样是历史遗留问题，各浏览器的兼容也是一个很大的难题，虽然我们很希望所有的浏览器的表现都一样，所写的代码在各浏览器都运行正常，但是目前的形式并不是我们理想的那样，有时候我们很多代码是为了适应各种浏览器而写的（当然，未来是光明的，未来肯定不会再有这么多问题）。多浏览器的兼容我觉得主要靠经验积累，因为你可能会遇到各种不同的情况，这里提供一些经验参考。 知乎上关于浏览器兼容性的讨论 前端工程师如何系统地整理和累积兼容性相关的知识？ 这里还有一点需要介绍，也是新人必须学习的，那就是调试技巧，调试也是开发过程中最重要的环节。我个人常用的调试工具还是用Chrome的Developer Tools，如果用FireFox，那么调试工具就是使用FireBug，如果是IE，似乎就是用自带的开发者工具，这些调试工具的使用大致相同，都可以通过F12键调出（Mac下不是的），调试代码也是经验的积累，前期掌握调试的步骤就可以了。 3. 时下热门 前端发展到现在已经要进入了一个爆炸式的时期了，要学习和掌握的技能太多了，而这一切都是因为NodeJs的异军突起。不过在学习NodeJ之前，可以先看看一些常见的CSS框架和JS框架，这些框架可以帮助我们更好地布局或者更好的码代码。 BootStrap 这个是现在非常火的一个框架，由Twitter开发，让那些即使不太会前端的人也能开发出不错的布局和界面。 AngularJs 同样也是一个很火的JS框架，由Google开发，其数据双向绑定功能非常吸引人，能大量减少开发者的工作量，Gmail就是非常成功的一个转型。 ReactJs 今年特别火的一个JS框架，由Facebook开发，其背后也是有很多故事，这个东西也是非常新，自己还没有去学习，不做过多介绍。 RequireJs/SeaJs 都是模块化开发的工具，让代码的组织性更强，不再杂乱无章。 NodeJs 无疑是当前最火的一个点，从NodeJs后诞生出了很多新的技术，不过NodeJs的学习还是比较快的，因为代码都是js。 Grunt/Gulp 在NodeJs出来之前很多的自动化工具都是基于Ant的，但是现在有了NodeJs后这2个自动化工具就变得非常火热，这些自动化工具可以一键完成各种任务，包括代码检查、代码压缩和合并等等。 CoffeeScript 一门编译到 JavaScript 的小巧语言，它尝试用简洁的方式展示 JavaScript 优秀的部分。还有后来发展的TypeScript Less/Sass/Stylus 这些是css的预编译语言，也是为了更好的书写CSS。 4. 展望未来 因水平有限，此处也不做过多展望，免得误导大家，不过可以知道的是前端的发展速度太快，不跟紧脚步就会赶不上大部队，别人说的东西你就不懂了，这里给出一个Github里的流行趋势，在这里可以看到现在有哪些东西比较热门，总的来说学习前端就要保持一个时刻学习的心。 再说说前端演化的发展吧，一个是混合开发（Hybrid App），其中以Ionic和HBuilder/HTML5+/mui为代表，还有一个是NodeJs桌面级应用开发。这些都可以作为前端学习道路中的一个分支吧，也会是一个不错的方向。 这里有一个别人推荐的网站，我看了觉得还是挺不错的，也是推荐给大家菜鸟教程。还有一个很有意思的Web Developer技能树，像玩游戏一样查看自己的技能结构。","link":"/road-to-frontend.html"},{"title":"服务器数据备份方案","text":"由于服务器买的是一年，而一年后可能有各种不确定性因素，再加上可能的一些误操作，所以之前建立的DevOps环境以及Bitwarden需要做一个备份。正好家里有黑群晖，就用它做数据备份吧。 最新备份方案 由于之前一直是用家里的 nas 进行备份，导致不怎么用的 nas 一直开机且无法进入自动休眠模式，心疼，所以打算切换到线上备份方案。原本打算用 api 对接各种云服务，自己 coding，但忽然想起不是有最厉害的开源多端云同步工具rclone么！那就用它做来备份吧。 安装 按照官网教程，在服务器上安装rclone 1curl https://rclone.org/install.sh | sudo bash 然后配置各种用来备份的远程 config，此处具体可以搜索。 加密 如果希望对某个备份目录进行加密，例如bitwarden，那么可以在 config 添加后继续添加一个 config，type选择crypt，目录填需要备份的config:path，例如OneDrive:/server/backup/path/to/bitwarden，后续的配置就按需填写。之后上传到该目录的文件就是加密的。 添加备份脚本 新建一个backup.sh脚本文件，内容如下 123456#!/usr/bin/env bashrclone --checksum sync /path/to/gogs/ GoogleDisk:/server/backup/path/to/gogs --exclude &quot;*.{swp}&quot; --exclude &quot;{log,tmp,sessions}/&quot; ;rclone --checksum sync /path/to/bitwarden/ GoogleDisk:/server/backup/path/to/bitwarden ;rclone --checksum sync /path/to/devops/gogs/ OneDrive:/server/backup/path/to/gogs --exclude &quot;*.{swp}&quot; --exclude &quot;{log,tmp,sessions}/&quot; ;rclone --checksum sync /path/to/bitwarden/ OneDrive:/server/backup/path/to/bitwarden# 可继续添加任意多个备份服务，前提是你在rclone config里配置好的 添加备份 service 在/usr/lib/systemd/system目录下新建backup.service，内容如下 12345678[Unit]Description=BackupTimer[Install]WantedBy=multi-user.target[Service]ExecStart=/bin/bash /path/to/backup.sh 在/etc/systemd/system/目录新建backup.timer，内容如下 123[Timer]OnCalendar=*-*-* 04:00:00Unit=backup.service 启动 service 12systemctl start backupsystemctl enable backup 以下内容为旧版备份方案 Gogs 备份 将备份服务器的 ssh key 添加到 gogs 服务器上，使用rsync进行备份，并添加定时脚本。 1nohup rsync -e &quot;ssh -p ssh-port&quot; -avL --delete --exclude &quot;gogs/log&quot; --exclude &quot;gogs/data/sessions&quot; user@gogs.erguotou.me:/user/devops/gogs /path/to/backup &gt;&gt; gogs.rsync.log 2&gt;&amp;1 &amp; Drone 备份 无需备份 Docker registry 备份 我是觉得没必要备份，大不了再打包运行一次 Bitwarden 备份 类似 gogs 的备份 1nohup rsync -e &quot;ssh -p 22&quot; -avL --delete user@gogs.erguotou.me:/user/bitwarden/data/ /path/to/backup &gt;&gt; bitwarden.rsync.log 2&gt;&amp;1 &amp;","link":"/server-data-backup.html"},{"title":"一些备忘","text":"登录到ssh 1ssh git@127.0.0.1 查看版本和远程url 1git remote -v git迁移 1.clone一份或者直接在原本地工程上开始 2.git remote set-url origin &lt;url&gt; url为目标迁移的git地址 3.git push origin master 将本地资源push到远程 bing每日背景请求地址","link":"/some-remark.html"},{"title":"服务器安全登录","text":"搬瓦工的VPS要到期了，以前用着好难受的感觉，所以决定加点钱换个好点的，最后还是买了Linode。这里记录一下以一个更安全的方式连接VPS的设置过程。 新建用户 首先新建用户，不使用root用户登录 1useradd -g root erguotou 设置密码 1passwd erguotou 添加到root组（不确定该步骤是否必须） 1vi /etc/sudoers 找到 12## Allow root to run any commands anywhereroot ALL=(ALL) ALL 在下面添加 1erguotou ALL=(ALL) ALL 使用公私钥方式登录 首先退出root用户，使用新建的用户登录，然后在用户目录下新建.ssh/authorized_keys文件。 123mkdir ~/.sshtouch ~/.ssh/authorized_keyschmod 700 ~/.ssh 然后复制本机的公钥内容添加到VPS的authorized_keys文件中，保存，退出登录，重新登录后就可以不用输入密码了。 禁root禁密码登录 使用root用户执行 1vi /etc/ssh/sshd_config 找到PasswordAuthentication配置，并改为no 1PasswordAuthentication no 找到PermitRootLogin配置，并改为no 1PermitRootLogin no 最后退出当前用户登录，然后尝试使用root登录，再尝试是否可以用密码方式登录。","link":"/ssh-via-public-key.html"},{"title":"SVN、GIT数据迁移","text":"SVN数据迁移 svn的管理使用的是Collabnet Subversion Edge。 1.安装服务 在目标机器上安装Collabnet Subversion Edge,简称CSE 2.复制版本库 将旧服务器上的repository全部复制到新服务器上 3.导入数据 在新服务器上打开CSE的管理后台http://localhost:3343/csvn， 在“版本库”页面选择“发现版本库”，这样就把之前的版本库都导入进去了 4.复制用户数据 从原机器中拷贝{安装路径} \\data\\conf下的svn_auth_file文件到新机器 5.导入用户数据 修改新机器{安装路径}\\data\\csvn-production-hsqldb.script文件。复制原机器中类似 INSERT INTO USER VALUES(1,2,'admin user','admin@example.com',TRUE,'f52c7457507a292a11bf8d274d720ee4','Super Administrator','admin') 的语句到新服务器的对应文件。 6.重置用户密码 7.重启CSE服务即可 GIT数据迁移 GIT的数据迁移比较简单，GIT是采用mysmgit+copssh搭建的。 1.安装环境 新机器上搭建GIT环境，并建立每个需要备份的项目的空仓库（好像不新建也是可以的） 2.GIT仓库转移 选择一份最新版本的项目路径，执行 git remote set-url origin 资源库地址 3.GIT提交 直接将当前项目提交即可，这样新的仓库里也是有之前所有的提交记录的","link":"/svn-git-transfer.html"},{"title":"vsftpd的安装配置","text":"参考自http://www.cnblogs.com/whoamme/p/3494128.html 安装相关工具包 1yum -y install pam vsftpd db4 db4-utils 创建一个不能登录的用户，用作ftp服务的虚拟用户 1useradd -d /home/xxx -s /sbin/nologin vuser_ftp /home/xxx为用户根目录，/sbin/nologin指定用户不能使用shell，该账号不能用于登录系统 这里使用vuser_ftp作为虚拟用户的映射对象，在web服务器中可以使用httpd 这个服务的用户来作为虚拟用的映射。比如www apapche web，没大明白~ 3. 创建一个记录ftp虚拟用户的用户名和密码文件，如login.txt 第一行用户名，第二行密码，以此类推 12345vi /etc/vsftpd/login.txtuser1pwd1user2pwd2 使用db_load 命令生成虚拟用户认证文件 1db_load -T -t hash -f /etc/vsftpd/login.txt /etc/vsftpd/vsftpd_login.db vsftpd_login.db文件是db_load命令生成的虚拟用户认证文件 5. 备份vsftpd配置文件，再修改配置文件 123456789101112131415161718192021222324vi /etc/vsftpd/vsftpd.confanonymous_enable=NOlocal_enable=YESwrite_enable=YESlocal_umask=022dirmessage_enable=YESxferlog_enable=YESconnect_from_port_20=YESxferlog_file=/var/log/vsftpd.logxferlog_std_format=YESlisten=YESuserlist_enable=YEStcp_wrappers=YESmax_per_ip=5max_clients=100#### 下面是关于虚拟用户的配置guest_enable=YES #打开用户虚拟guest_username=vuser_ftp #将所有虚拟用户映射成vuer_ftp这个本地用户#此用户是之前新建的用户pam_service_name=ftp.vu #ftp用户的pam验证方式，默认是vsftpd，必须改掉。user_config_dir=/etc/vsftpd/vsftpd_user_conf #这里放置每个虚拟用户的配置文件 创建vsftpd.conf中提到的验证文件 使用rpm -ql vsftpd这个命令查找验证模块的例文，找到如下一段 1/usr/share/doc/vsftpd-2.2.2/EXAMPLE/VIRTUAL_USERS/vsftpd.pam 将其拷贝到vsftpd.conf文件中配置的路径中并改变文件名 1cp /usr/share/doc/vsftpd-2.2.2/EXAMPLE/VIRTUAL_USERS/vsftpd.pam /etc/pam.d/ftp.vu 前面配置中的pam_service_name=ftp.vu中ftp.vu使用的是相对路径，绝对路径是/etc/pam.d/ftp.vu 上面这条命令就是把vsftpd程序自带的关于pam认证的模板文件拷贝到pam.d这个服务的工作目录，同时改变文件名为ftp.vu。 /etc/pam.d/目录下已经有了一个vsftpd.pam文件，现在要做的是让vsftpd虚拟用户的这个功能用到的一个特殊的pam认证。还要修改下ftp.vu这个文件 先来看下原文件的内容： 1234vi /usr/share/doc/vsftpd-2.2.2/EXAMPLE/VIRTUAL_USERS/vsftpd.pamauth required /lib/security/pam_userdb.so db=/etc/vsftpd/loginaccount required /lib/security/pam_userdb.so db=/etc/vsftpd/login 将两处的db=/etc/vsftpd/login修改成db=/etc/vsftpd/vsftpd_login，文件都是以.db结尾的，但此处不要填写.db。同时由于我们的系统是64位的，还需要将配置中间的/lib/改为/lib64/ 1234vi /etc/pam.d/ftp.vuauth required /lib64/security/pam_userdb.so db=/etc/vsftpd/vsftpd_loginaccount required /lib64/security/pam_userdb.so db=/etc/vsftpd/vsftpd_login 创建vsftpd.conf中提到的虚拟用户配置目录user_config_dir=/etc/vsftpd/vsftpd_user_conf，以及在这个目录下面创建每个用户的权限配置文件 创建/etc/vsftpd/vsftpd_user_conf目录 1mkdir /etc/vsftpd/vsftpd_user_conf 在/etc/vsftpd/vsftpd_user_conf目录下面分别创建之前在login.txt虚拟用户名和密码文件中提到的user1 user2 这两个虚拟用户的权限配置文件 12345678vi /etc/vsftpd/vsftpd_user_conf/user1anon_world_readable_only=no #用户可以浏览和下载文件，不能设为yes，否则无法看到文件write_enable=yes #用户可以创建文件anon_upload_enable=yes #用户可以上传文件anon_mkdir_write_enable=yes #用户有创建和删除目录的权限anon_other_write_enable=yes #用户具有文件改名和删除文件的权限local_root=/home/xxx #指定这个虚拟FTP用户的家目录。这里的xxx是你网站的根目录 之后再创建user2的权限文件（略） 8. OK！结束！重启vsftpd服务 1service vsftpd restart","link":"/vsftpd-config.html"},{"title":"微信小程序开发填坑整理","text":"open-data显示头像，希望加圆角，直接使用border-radius不生效，需要再加overflow:hidden，猜测为open-data下还有子节点，而图片在子节点上，必须在父节点上加overflow:hidden来隐藏超出部分 picker上设置flex一类的样式无法直接应用到子节点上，需要在picker内部再套一层带样式的view，原因同上。例如123456&lt;picker&gt; &lt;view class=&quot;flex ai-center&quot;&gt; &lt;view class=&quot;child1&quot;&gt;&lt;/view&gt; &lt;view class=&quot;child2&quot;&gt;&lt;/view&gt; &lt;/view&gt;&lt;/picker&gt; 部分原生组件上无法使用svg图片地址，例如map组件的markers使用svg图片在模拟器上能显示在真机上显示不出来。其它的一些组件也有可能会有。 想要在小程序上实现表格组件，第一时间想到的可能是flex布局，但是flex布局无法保证td和th在不设置具体宽度的情况下保持相同宽度。其次可能会想到用grid布局，但是小程序对grid布局的兼容性无法保证。最后能想到的就是用table布局了。 但随着业务开发，发现简单的数据渲染已经无法满足了，可能还需要支持类似web上自定义render的功能，但小程序不支持scoped-slot，思来想去只能用slot加索引的方式实现。最后还有个默认空数据的提示，由于不支持colspan属性，只能用hack方式实现。具体table组件代码可参考如下（mpx组件）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111&lt;template&gt; &lt;view class=&quot;table relative&quot;&gt; &lt;view class=&quot;tr&quot;&gt; &lt;view wx:for=&quot;{{computedColumns}}&quot; wx:key=&quot;index&quot; class=&quot;th&quot; wx:style=&quot;{{{textAlign:item.align,width:item.width}}}&quot;&gt; {{item.title}} &lt;/view&gt; &lt;/view&gt; &lt;view wx:if=&quot;{{!data.length}}&quot; class=&quot;tr placeholder&quot;&gt; &lt;view wx:for=&quot;{{computedColumns}}&quot; wx:key=&quot;index&quot; class=&quot;td&quot;&gt; &lt;/view&gt; &lt;view class=&quot;placeholder-text&quot;&gt;{{placeholder}}&lt;/view&gt; &lt;/view&gt; &lt;view wx:for=&quot;{{data}}&quot; wx:for-index=&quot;rowIndex&quot; wx:for-item=&quot;row&quot; wx:key=&quot;rowIndex&quot; class=&quot;tr&quot;&gt; &lt;view wx:for=&quot;{{computedColumns}}&quot; wx:key=&quot;index&quot; class=&quot;td&quot; wx:style=&quot;{{{textAlign:item.align,width:item.width}}}&quot;&gt; &lt;slot wx:if=&quot;{{item.slot}}&quot; name=&quot;col_{{rowIndex}}&quot; /&gt; &lt;block wx:else&gt;{{ data[rowIndex][item.key]}}&lt;/block&gt; &lt;/view&gt; &lt;/view&gt; &lt;/view&gt;&lt;/template&gt;&lt;script&gt;import { createComponent } from '@mpxjs/core'export default createComponent({ options: { styleIsolation: 'apply-shared', multipleSlots: true }, properties: { /** * [{ * title:'', * key:'', * width:?rpx, * align: 'left/center/right' * }] */ columns: { type: Array, value: [] }, data: { type: Array, value: [] }, placeholder: { type: String, value: '暂无数据' } }, computed: { computedColumns() { return this.columns.map(col =&gt; { return { ...col, width: typeof col.width === 'number' ? `${col.width}rpx` : col.width } }) } }})&lt;/script&gt;&lt;script type=&quot;application/json&quot; lang=&quot;json&quot;&gt;{ &quot;component&quot;: true}&lt;/script&gt;&lt;style lang=&quot;stylus&quot;&gt;@import '~@/assets/styles/variables.styl'.table { display table width 100% border-collapse: collapse; .tr { width: 100%; display table-row } .th, .td { display table-cell padding 20rpx 8rpx width auto vertical-align middle font-size 24rpx color $darkTextColor } .th { color $greyTextColor } .td { border-top 1px solid $dividerColor } .placeholder { .td { height: 72rpx; } } .placeholder-text { position absolute left 50% top 92rpx font-size 24rpx color $placeholderColor transform translateX(-50%) }}&lt;/style&gt;","link":"/wechat-mina-note.html"},{"title":"利用Traefik搭建超简单的DevOps平台","text":"又是好久没有写博客了，忽然有点自己不知道继续往哪个方向发展，一会搞搞Flutter，一会又玩玩Docker，有时又想做些框架沉淀，很多东西都没深入做下去。正好之前搞的DevOps平台最近需要做些扩展，就花点时间把这次经验记录下来方便以后查看😂。 首先，做什么？为什么做？ 还是DevOps，还是为了简化开发，还是低端机器，所以选择的方案依然是Gogs+drone。但是这次的方案有别于之前的Dokku，而是使用traefik作为网关服务器并且提供自动设置HTTPS的功能。先看下什么是traefik： Traefik 是一个边缘路由器，这意味着它是您平台的大门，它拦截并路由每个传入的请求: 它管理所有逻辑和每个规则确定哪些服务处理哪些请求（基于路径，主机，headers，等等…）。 traefik支持服务自动发现，当我们在Docker上使用traefik时，只需给Docker容器指定Label，就可以让traefik自动发现它们，自动完成端口映射、域名绑定、HTTPS证书管理等🤔。 所以基于traefik的部署方案可以让我们省去很多配置工作（比如Nginx的配置，Let’s Encrypt的证书申请和更新，负载均衡等），当然也留给了我们很多坑…😟 其次，准备阶段 一个1核2G2M的云服务器，ssh登录上，安装docker，安装docker-compose，这些官网都有教程，很简单，掠过。 然后我们先提前做好域名映射，如果你使用traefik的dnsChallenge方式可以跳过，traefik会利用api自动为你做好域名映射（应该是吧，反正我没用过，我更喜欢自己把控🤔）： 123456traefik.erguotou.me -&gt; ipwhoami.erguotou.me -&gt; ipgogs.erguotou.me -&gt; ipdrone.erguotou.me -&gt; ipregistry.erguotou.me -&gt; ipregistry-ui.erguotou.me -&gt; ip 然后我们新建.env文件，并填入下面内容 12345678910111213141516171819# 顶级域名，此处替换成自己的SERVER_DOMAIN=erguotou.me# Time ZoneTIME_ZONE=Asia/Shanghai# ACME，此处替换成自己的ACME_EMAIL=xxx# Drone，此处替换成自己的DRONE_SECRET=xxxDRONE_ADMIN=xxx# basicauth用户密码# 使用 echo $(htpasswd -nb user password) 生成用户密钥# 如果直接在yml中使用需要改为 echo $(htpasswd -nb user password) | sed -e s/\\\\$/\\\\$\\\\$/gTRAEFIK_AUTH_USER=xxxREGISTRY_AUTH_USER=xxxREGISTRY_UI_AUTH_USER=xxx 接着新建一个docker-compose.yml文件，并填入下面内容 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# 目前最新版本，可以支持更多特性，虽然我可能也没用上啥特性version: &quot;3.7&quot;services: traefik: # The official docker image image: traefik:latest container_name: traefik # Enables the web UI and tells Traefik to listen to docker command: # 提供web查看页面 - &quot;--api.insecure=true&quot; # 使用docker provider - &quot;--providers.docker=true&quot; # 取消暴露所有的容器，由我们自己把控 - &quot;--providers.docker.exposedbydefault=false&quot; # 定义websecure - &quot;--entryPoints.websecure.address=:443&quot; # 使用tlschallenge方式进行https证书管理，当前也可以使用httpChallenge或者dnsChallenge - &quot;--certificatesresolvers.mytlschallenge.acme.tlschallenge=true&quot; # - &quot;--certificatesResolvers.mytlschallenge.acme.httpchallenge.entryPoint=web&quot; # 指定Let's Encrypt证书获取所使用的邮箱地址 - &quot;--certificatesResolvers.mytlschallenge.acme.email=${ACME_EMAIL}&quot; # acme.json文件存储位置（容器内），方便后续暴露出来 - &quot;--certificatesResolvers.mytlschallenge.acme.storage=/etc/acme/acme.json&quot; ports: - &quot;443:443&quot; # The Web UI (enabled by --api.insecure=true) - &quot;8080:8080&quot; volumes: - &quot;./acme:/etc/acme&quot; # So that Traefik can listen to the Docker events - &quot;/var/run/docker.sock:/var/run/docker.sock:ro&quot; environment: - TZ=${TIME_ZONE} # 先启用一个官方示例的容器 whoami: image: containous/whoami container_name: simple-service labels: - &quot;traefik.enable=true&quot; # 告诉traefik映射80端口 - &quot;traefik.http.services.whoami.loadbalancer.server.port=80&quot; - &quot;traefik.http.routers.whoami.rule=Host(`whoami.${SERVER_DOMAIN}`)&quot; # 告诉traefik入口方式使用https - &quot;traefik.http.routers.whoami.entrypoints=websecure&quot; - &quot;traefik.http.routers.whoami.tls.certresolver=mytlschallenge&quot; 最后运行docker-compose up运行，我们看到http://traefik.erguotou.me:8080/dashboard/和https://whoami.erguotou.me/都可以正常访问，并且在traefik的Dashboard里可以看到成功纳管了一个Router。 再次，尝试与填坑 初步测试成功后我们开始搭建我们的DevOps平台，我们在原来的docker-compose.yml文件中追加以下内容 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114version: &quot;3.7&quot;services: # ...原来的内容，下面是新增的 # gogs gogs: container_name: gogs image: gogs/gogs restart: always hostname: gogs ports: - &quot;10022:22&quot; volumes: - ./devops/gogs:/data environment: - TZ=${TIME_ZONE} labels: - &quot;traefik.enable=true&quot; - &quot;traefik.http.services.gogs.loadbalancer.server.port=3000&quot; - &quot;traefik.http.routers.gogs.rule=Host(`gogs.${SERVER_DOMAIN}`)&quot; - &quot;traefik.http.routers.gogs.entrypoints=websecure&quot; - &quot;traefik.http.routers.gogs.tls.certresolver=mytlschallenge&quot; # drone 服务端 drone-server: container_name: drone-server image: drone/drone restart: always hostname: drone-server volumes: - ./devops/drone-server:/var/lib/drone/ environment: - TZ=${TIME_ZONE} - DRONE_GOGS_SERVER=https://gogs.${SERVER_DOMAIN} - DRONE_RPC_SECRET=${DRONE_SECRET} - DRONE_SERVER_HOST=drone.${SERVER_DOMAIN} - DRONE_SERVER_PROTO=https # 设置管理员 - DRONE_USER_CREATE=username:${DRONE_ADMIN},admin:true labels: - &quot;traefik.enable=true&quot; - &quot;traefik.http.routers.drone-server.rule=Host(`drone.${SERVER_DOMAIN}`)&quot; - &quot;traefik.http.routers.drone-server.entrypoints=websecure&quot; - &quot;traefik.http.routers.drone-server.tls.certresolver=mytlschallenge&quot; # drone agent drone-agent: container_name: drone-agent image: drone/agent restart: always hostname: drone-agent depends_on: # 让server先起 - drone-server # deploy: # mode: replicated # replicas: 6 volumes: - /var/run/docker.sock:/var/run/docker.sock environment: - TZ=${TIME_ZONE} - DRONE_RPC_HOST=drone.${SERVER_DOMAIN} - DRONE_RPC_SECRET=${DRONE_SECRET} - DRONE_SERVER_PROTO=https # 一台机器最多同时跑2个任务 - DRONE_RUNNER_CAPACITY=2 # - DRONE_RUNNER_NAME=${HOSTNAME} labels: # agent不需要对外暴露 - &quot;traefik.enable=false&quot; # docker registry registry: container_name: registry image: registry restart: always hostname: registry volumes: - ./devops/registry:/var/lib/registry environment: - TZ=${TIME_ZONE} - REGISTRY_STORAGE_DELETE_ENABLED=true labels: - &quot;traefik.enable=true&quot; - &quot;traefik.http.routers.registry.rule=Host(`registry.${SERVER_DOMAIN}`)&quot; - &quot;traefik.http.routers.registry.entrypoints=websecure&quot; - &quot;traefik.http.routers.registry.tls.certresolver=mytlschallenge&quot; - &quot;traefik.http.routers.registry.middlewares=registry-auth@docker&quot; - &quot;traefik.http.middlewares.registry-auth.basicauth.users=${REGISTRY_AUTH_USER}&quot; - &quot;traefik.http.middlewares.registry-auth.basicauth.removeheader=true&quot; # docker registry 可视化web页面 registry-ui: container_name: registry-ui image: quiq/docker-registry-ui #image: jc21/registry-ui #image: konradkleine/docker-registry-frontend:v2 restart: always hostname: registry-ui depends_on: - registry environment: - TZ=${TIME_ZONE} # 此处有个大坑，对于Dockerfile中没有暴露端口的，需要自己手动指定下暴露的端口，这样traefik才能检测到要映射哪个端口，否则不成功 expose: - 8000 volumes: - ./devops/registry-ui.yml:/opt/config.yml:ro labels: - &quot;traefik.enable=true&quot; # 添加一个basic auth - &quot;traefik.http.middlewares.registry-ui-auth.basicauth.users=${REGISTRY_UI_AUTH_USER}&quot; - &quot;traefik.http.middlewares.registry-ui-auth.basicauth.removeheader=true&quot; - &quot;traefik.http.services.registry-ui.loadbalancer.server.port=8000&quot; - &quot;traefik.http.routers.registry-ui.rule=Host(`registry-ui.${SERVER_DOMAIN}`)&quot; - &quot;traefik.http.routers.registry-ui.entrypoints=websecure&quot; - &quot;traefik.http.routers.registry-ui.tls.certresolver=mytlschallenge&quot; - &quot;traefik.http.routers.registry-ui.middlewares=registry-ui-auth@docker&quot; 对于registry-ui镜像的选择，原来用的是konradkleine/docker-registry-frontend:v2，后来也试过jc21/registry-ui，但是容器体积都比较大，最后换了go语言的quiq/docker-registry-ui（每种镜像的配置稍有差异）要知道在小内存服务器上，Golang一条线才是正道😂。 除此之外我们给registry和registry-ui加了一个traefik提供的baisicauth中间件，帮助我们添加一层安全认证，只有指定的用户可以查看，方便👍！同时配置中提到的registry-ui.yml文件的内容如下（去掉了很多注释，具体可以看容器的文档说明）： 123456789101112131415161718listen_addr: 0.0.0.0:8000base_path: /registry_url: https://registry.erguotou.meverify_tls: true# 更换成自己的registry_username: userregistry_password: passevent_database_driver: sqlite3event_database_location: data/registry_events.dbevent_deletion_enabled: Falsecache_refresh_interval: 10anyone_can_delete: falseadmins: []debug: falsepurge_tags_keep_days: 90purge_tags_keep_count: 2purge_tags_schedule: '' 我们开始启动服务docker-compose up，然后打开gogs.erguotou.me开始配置gogs，同时drone,registry,registry-ui服务也都起好了。 等等，不是说好多坑么？Emmmmm~ 我这都是坑填完了得出的配置，traefik文档也不知道看了多少次，配置试了多少次。😅 一切看起来那么的美好😏 接着，深入与实践 虽然服务都启动了，但还有些可以优化的点，并且我们还要验证下整个DevOps流程是否可以跑通，尤其是drone的agent我们还没有验证呢。在这之前我们先将配置文件分离下，按功能将docker-compose.yml中的service分开到多个文件中分别启动。 服务拆分 删除初始版本中的whoami服务 在devops目录新增docker-compose.yml文件，将后续添加的services剪切到yml文件中（yml文件中services和version根节点也要复制） 修改devops/docker-compose.yml中volumns中映射路径 分别启动docker-compose up -d和docker-compose -f ./devops/docker-compose.yml up -d 这里关于.env文件我做了一些测试，发现在traefik同级创建的.env文件在devops目录中不做任何操作可以直接访问到里面的环境变量，之前还一直以为需要手动指定呢。 另外上面的环境变量其实是不对了，原来的.env文件是当前目录下的，但是现在目录结构变了，所以那些环境变量就取不到了。 其实有很多方法可以实现环境变量共享，本来打算用extends env_file实现的，结果compose 3版本后不支持了，那就采用每个service指定env_file的方案吧（虽然有点麻烦），修改完重新启动。 访问不了？先看下traefik的路由表，发现有接入，但就是访问不了。无意间在查看registry-ui的启动日志时发现错误，说registry.erguotou.me访问不了。这是为什么呢？又是一番搜索排查尝试，最终发现当devops services和traefik service不在同一个文件时，我们需要让它们加入同一个网络，这样子traefik才可以完成自动代理。于是我们开始给traefik服务关联网络，给devops里的各种服务也绑定同样的网络。同时需要添加新的labeltraefik.docker.network=traefik_webgateway。改完重启，一切OK（最终配置可查看下文）。 给Traefik增加安全性 现在我们的traefik开启了8080的Dashboard，意味着别人也能看到我们的内容，所以在生产环境下我们需要关闭traefik的api服务，或者至少我们需要给api加一层认证。 关闭的话直接在traefik的service中把--api.insecure=true改为--api=false即可。 如果想看Dashboard又想安全性可以用上面说到的basic auth套一层， 验证DevOps流程 这里我们以一个简单的vue项目做测试看下如何实现devops自动化。 在gogs上新建一个临时项目/tmp/vue-demo 在本地使用Vue cli创建一个demo项目，并上传到git服务。此时不会触发任何后续操作 添加.drone.yml，推送到仓库，yml文件内容大致如下 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647---kind: pipelinename: defaulttrigger: event: - tagsteps: - name: build image: plugins/docker settings: dockerfile: docker/Dockerfile registry: registry.erguotou.me repo: registry.erguotou.me/tmp/vue-demo username: from_secret: REGISTRY_USER password: from_secret: REGISTRY_PASSWORD tags: - latest - ${DRONE_TAG} auto_tag: true force_tag: true - name: deploy image: appleboy/drone-ssh settings: host: vue-demo.erguotou.me username: from_secret: SSH_USER ssh_key: from_secret: SSH_KEY script: # 在机器上执行一次login操作，以后就不用了 # - docker login registry.erguotou.me --username ${REGISTRY_USER} --password ${REGISTRY_PASSWORD} - docker pull registry.erguotou.me/tmp/vue-demo:${DRONE_TAG} - docker-compose -f apps/vue-demo/docker-compose.yml stop - docker-compose -f apps/vue-demo/docker-compose.yml rm -f - docker-compose -f apps/vue-demo/docker-compose.yml up -d - name: send-wechat image: yakumioto/drone-serverchan settings: key: from_secret: SERVERCHAN_KEY text: &quot;部署结果&quot; # 目前该插件支持能力稍微不足，后期可以考虑自己开发下 desp: &quot;部署完成，[点击前往查看](https://vue-demo.erguotou.me)&quot; 查看drone上的构建结果，查看registry是否推送成功，查看项目是否部署成功 ，最后结果可以成功，点击地址查看。 最终配置 最终docker-compose.yml文件内容如下： 123456789101112131415161718192021222324252627282930313233343536373839version: &quot;3.7&quot;services: traefik: image: traefik:latest container_name: traefik command: - &quot;--api=true&quot; - &quot;--api.dashboard=true&quot; - &quot;--providers.docker=true&quot; # 默认加入此网络，也许关联networks之后可以不设置？反正不关联networks其它的都映射不成功 - &quot;--providers.docker.network=traefik_webgateway&quot; - &quot;--providers.docker.exposedbydefault=false&quot; - &quot;--entryPoints.websecure.address=:443&quot; - &quot;--certificatesresolvers.mytlschallenge.acme.tlschallenge=true&quot; - &quot;--certificatesResolvers.mytlschallenge.acme.email=${ACME_EMAIL}&quot; - &quot;--certificatesResolvers.mytlschallenge.acme.storage=/etc/acme/acme.json&quot; labels: - &quot;traefik.enable=true&quot; - &quot;traefik.http.routers.api.rule=Host(`traefik.${SERVER_DOMAIN}`)&quot; - &quot;traefik.http.routers.api.service=api@internal&quot; - &quot;traefik.http.services.api.loadbalancer.server.port=8080&quot; - &quot;traefik.http.routers.api.entrypoints=websecure&quot; - &quot;traefik.http.routers.api.tls.certresolver=mytlschallenge&quot; - &quot;traefik.http.routers.api.middlewares=auth&quot; - &quot;traefik.http.middlewares.auth.basicauth.users=${TRAEFIK_AUTH_USER}&quot; networks: - traefik_webgateway ports: - &quot;443:443&quot; volumes: - &quot;./acme:/etc/acme&quot; - &quot;/var/run/docker.sock:/var/run/docker.sock:ro&quot; environment: - TZ=${TIME_ZONE}networks: traefik_webgateway: name: traefik_webgateway driver: bridge devops/docker-compose.yml文件内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125version: &quot;3.7&quot;services: # gogs gogs: container_name: gogs image: gogs/gogs restart: always hostname: gogs networks: - traefik ports: - &quot;10022:22&quot; volumes: - ./gogs:/data environment: - TZ=${TIME_ZONE} labels: - &quot;traefik.enable=true&quot; - &quot;traefik.http.services.gogs.loadbalancer.server.port=3000&quot; - &quot;traefik.http.routers.gogs.rule=Host(`gogs.${SERVER_DOMAIN}`)&quot; - &quot;traefik.http.routers.gogs.entrypoints=websecure&quot; - &quot;traefik.http.routers.gogs.tls.certresolver=mytlschallenge&quot; # drone 服务端 drone-server: container_name: drone-server image: drone/drone restart: always hostname: drone-server networks: - traefik volumes: - ./drone-server:/var/lib/drone/ environment: - TZ=${TIME_ZONE} - DRONE_GOGS_SERVER=https://gogs.${SERVER_DOMAIN} - DRONE_RPC_SECRET=${DRONE_SECRET} - DRONE_SERVER_HOST=drone.${SERVER_DOMAIN} - DRONE_SERVER_PROTO=https # 设置管理员 - DRONE_USER_CREATE=username:${DRONE_ADMIN},admin:true labels: - &quot;traefik.enable=true&quot; - &quot;traefik.http.routers.drone-server.rule=Host(`drone.${SERVER_DOMAIN}`)&quot; - &quot;traefik.http.routers.drone-server.entrypoints=websecure&quot; - &quot;traefik.http.routers.drone-server.tls.certresolver=mytlschallenge&quot; # drone agent drone-agent: container_name: drone-agent image: drone/agent restart: always hostname: drone-agent depends_on: # 让server先起 - drone-server # deploy: # mode: replicated # replicas: 6 networks: - traefik volumes: - /var/run/docker.sock:/var/run/docker.sock environment: - TZ=${TIME_ZONE} - DRONE_RPC_HOST=drone.${SERVER_DOMAIN} - DRONE_RPC_SECRET=${DRONE_SECRET} - DRONE_SERVER_PROTO=https # 一台机器最多同时跑2个任务 - DRONE_RUNNER_CAPACITY=2 # - DRONE_RUNNER_NAME=${HOSTNAME} labels: # agent不需要对外暴露 - &quot;traefik.enable=false&quot; # docker registry registry: container_name: registry image: registry restart: always hostname: registry networks: - traefik volumes: - ./registry:/var/lib/registry environment: - TZ=${TIME_ZONE} - REGISTRY_STORAGE_DELETE_ENABLED=true labels: - &quot;traefik.enable=true&quot; - &quot;traefik.http.routers.registry.rule=Host(`registry.${SERVER_DOMAIN}`)&quot; - &quot;traefik.http.routers.registry.entrypoints=websecure&quot; - &quot;traefik.http.routers.registry.tls.certresolver=mytlschallenge&quot; - &quot;traefik.http.routers.registry.middlewares=registry-auth@docker&quot; - &quot;traefik.http.middlewares.registry-auth.basicauth.users=${REGISTRY_AUTH_USER}&quot; - &quot;traefik.http.middlewares.registry-auth.basicauth.removeheader=true&quot; # docker registry 可视化web页面 registry-ui: container_name: registry-ui image: quiq/docker-registry-ui restart: always hostname: registry-ui networks: - traefik depends_on: - registry environment: - TZ=${TIME_ZONE} # 此处有个大坑，对于Dockerfile中没有暴露端口的，需要自己手动指定下暴露的端口，这样traefik才能检测到要映射哪个端口，否则不成功 expose: - 8000 volumes: - ./registry-ui.yml:/opt/config.yml:ro labels: - &quot;traefik.enable=true&quot; - &quot;traefik.http.services.registry-ui.loadbalancer.server.port=8000&quot; - &quot;traefik.http.routers.registry-ui.rule=Host(`registry-ui.${SERVER_DOMAIN}`)&quot; - &quot;traefik.http.routers.registry-ui.entrypoints=websecure&quot; - &quot;traefik.http.routers.registry-ui.tls.certresolver=mytlschallenge&quot; - &quot;traefik.http.routers.registry-ui.middlewares=registry-ui-auth@docker&quot; - &quot;traefik.http.middlewares.registry-ui-auth.basicauth.users=${REGISTRY_UI_AUTH_USER}&quot; - &quot;traefik.http.middlewares.registry-ui-auth.basicauth.removeheader=true&quot;networks: traefik: external: name: traefik_webgateway traefik的Dashboard效果如下： 最后，总结 通过这么多天的不断学习和尝试，基本上填完了traefik作为网关路由器的坑，也让我学习了traefik的各种配置，最终组建了自己的DevOps平台。最终流程走通后心情非常舒畅，感觉完成了天大的事😂。 我们可以浅尝辄止，也可以深坑直入。这是自己的选择，也许也决定了自己的高度。 分享此文，给可能需要的人。","link":"/traefik-devops.html"}],"tags":[{"name":"Atom","slug":"Atom","link":"/tags/Atom/"},{"name":"Atom-plugin","slug":"Atom-plugin","link":"/tags/Atom-plugin/"},{"name":"Ghost","slug":"Ghost","link":"/tags/Ghost/"},{"name":"os","slug":"os","link":"/tags/os/"},{"name":"mac","slug":"mac","link":"/tags/mac/"},{"name":"openssh","slug":"openssh","link":"/tags/openssh/"},{"name":"centos","slug":"centos","link":"/tags/centos/"},{"name":"ci","slug":"ci","link":"/tags/ci/"},{"name":"travis ci","slug":"travis-ci","link":"/tags/travis-ci/"},{"name":"gitlab ci","slug":"gitlab-ci","link":"/tags/gitlab-ci/"},{"name":"comunion","slug":"comunion","link":"/tags/comunion/"},{"name":"cd","slug":"cd","link":"/tags/cd/"},{"name":"github actions","slug":"github-actions","link":"/tags/github-actions/"},{"name":"Cookie","slug":"Cookie","link":"/tags/Cookie/"},{"name":"Debug","slug":"Debug","link":"/tags/Debug/"},{"name":"electron-ssr","slug":"electron-ssr","link":"/tags/electron-ssr/"},{"name":"dokku","slug":"dokku","link":"/tags/dokku/"},{"name":"gogs","slug":"gogs","link":"/tags/gogs/"},{"name":"drone","slug":"drone","link":"/tags/drone/"},{"name":"CI","slug":"CI","link":"/tags/CI/"},{"name":"CD","slug":"CD","link":"/tags/CD/"},{"name":"electron","slug":"electron","link":"/tags/electron/"},{"name":"summary","slug":"summary","link":"/tags/summary/"},{"name":"eslint","slug":"eslint","link":"/tags/eslint/"},{"name":"optional chaining","slug":"optional-chaining","link":"/tags/optional-chaining/"},{"name":"Api","slug":"Api","link":"/tags/Api/"},{"name":"Vps","slug":"Vps","link":"/tags/Vps/"},{"name":"Raspberry","slug":"Raspberry","link":"/tags/Raspberry/"},{"name":"Swiftype","slug":"Swiftype","link":"/tags/Swiftype/"},{"name":"Git","slug":"Git","link":"/tags/Git/"},{"name":"Hexo","slug":"Hexo","link":"/tags/Hexo/"},{"name":"TravisCI","slug":"TravisCI","link":"/tags/TravisCI/"},{"name":"Firebase","slug":"Firebase","link":"/tags/Firebase/"},{"name":"Github","slug":"Github","link":"/tags/Github/"},{"name":"硬件","slug":"硬件","link":"/tags/%E7%A1%AC%E4%BB%B6/"},{"name":"3D打印","slug":"3D打印","link":"/tags/3D%E6%89%93%E5%8D%B0/"},{"name":"STM32","slug":"STM32","link":"/tags/STM32/"},{"name":"Arduino","slug":"Arduino","link":"/tags/Arduino/"},{"name":"windows","slug":"windows","link":"/tags/windows/"},{"name":"前端开发环境","slug":"前端开发环境","link":"/tags/%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/"},{"name":"Nginx","slug":"Nginx","link":"/tags/Nginx/"},{"name":"NodeJs","slug":"NodeJs","link":"/tags/NodeJs/"},{"name":"openwrt","slug":"openwrt","link":"/tags/openwrt/"},{"name":"adguard home","slug":"adguard-home","link":"/tags/adguard-home/"},{"name":"pppoe","slug":"pppoe","link":"/tags/pppoe/"},{"name":"Fonts","slug":"Fonts","link":"/tags/Fonts/"},{"name":"rancher","slug":"rancher","link":"/tags/rancher/"},{"name":"kubernetes","slug":"kubernetes","link":"/tags/kubernetes/"},{"name":"k8s","slug":"k8s","link":"/tags/k8s/"},{"name":"k3s","slug":"k3s","link":"/tags/k3s/"},{"name":"rancher os","slug":"rancher-os","link":"/tags/rancher-os/"},{"name":"Frontend","slug":"Frontend","link":"/tags/Frontend/"},{"name":"bitwarden","slug":"bitwarden","link":"/tags/bitwarden/"},{"name":"backup","slug":"backup","link":"/tags/backup/"},{"name":"rclone","slug":"rclone","link":"/tags/rclone/"},{"name":"SSH","slug":"SSH","link":"/tags/SSH/"},{"name":"vsftpd","slug":"vsftpd","link":"/tags/vsftpd/"},{"name":"wechat","slug":"wechat","link":"/tags/wechat/"},{"name":"小程序","slug":"小程序","link":"/tags/%E5%B0%8F%E7%A8%8B%E5%BA%8F/"},{"name":"traefik","slug":"traefik","link":"/tags/traefik/"},{"name":"devops","slug":"devops","link":"/tags/devops/"},{"name":"registry","slug":"registry","link":"/tags/registry/"}],"categories":[]}